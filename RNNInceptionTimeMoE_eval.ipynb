{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repo is ready at /content/Parkinsons_VGRF_Spatiotemporal_Diagnosis_v2\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import subprocess\n",
    "\n",
    "repo_url = 'https://github.com/alxxtexxr/Parkinsons_VGRF_Spatiotemporal_Diagnosis_v2.git'\n",
    "repo_name = repo_url.rstrip('.git').split('/')[-1] # Extract repo name from URL\n",
    "root_dir = '/content'\n",
    "repo_dir = os.path.join(root_dir, repo_name)\n",
    "\n",
    "# Clone only if repo doesn't exist\n",
    "if not os.path.isdir(repo_dir):\n",
    "    subprocess.run(['git', 'clone', '--no-checkout', repo_url], check=True, cwd=root_dir)\n",
    "    subprocess.run(['git', 'sparse-checkout', 'init', '--cone'], check=True, cwd=repo_dir)\n",
    "    subprocess.run(['git', 'sparse-checkout', 'set', 'src'], check=True, cwd=repo_dir)\n",
    "    subprocess.run(['git', 'checkout'], check=True, cwd=repo_dir)\n",
    "\n",
    "print(f\"Repo is ready at {repo_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tsai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tsai'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-48-617e0e84cff4>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mprint_h\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_window\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_person_majority_voting\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRNNInceptionTime\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mRNNInceptionTime\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/content/Parkinsons_VGRF_Spatiotemporal_Diagnosis_v2/src/models/RNNInceptionTime.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtsai\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtsai\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInceptionTime\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mInceptionBlock\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtsai\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtsai\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPermute\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mConcat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mGAP1d\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tsai'",
      "",
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "from datetime import datetime\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "from src.utils import print_h, eval_window, eval_person_majority_voting\n",
    "from src.models.RNNInceptionTime import RNNInceptionTime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def update_output(output, eval_output):\n",
    "    for metric in ['acc', 'f1', 'precision', 'recall', 'cm']:\n",
    "        output[metric]['folds'] += [eval_output[metric]]\n",
    "        if metric != 'cm':\n",
    "            output[metric]['avg'] = np.mean(output[metric]['folds'])\n",
    "            output[metric]['std'] = np.std(output[metric]['folds'])\n",
    "    return output\n",
    "\n",
    "class MoE(torch.nn.Module):\n",
    "    def __init__(self, experts, gate):\n",
    "        super(MoE, self).__init__()\n",
    "        self.experts = torch.nn.ModuleList(experts)\n",
    "        self.gate = gate\n",
    "\n",
    "    def forward(self, x):\n",
    "        gate_out = self.gate(x)\n",
    "        # print(f'{gate_out=}')\n",
    "        \n",
    "        gate_out_max_idxs = torch.argmax(gate_out, dim=1)\n",
    "        # _, gate_out_max_idxs = torch.max(gate_out, dim=1)\n",
    "\n",
    "        # gate_out_one_hot = torch.zeros_like(gate_out, dtype=torch.int)\n",
    "        # gate_out_one_hot.scatter_(1, gate_out_max_idxs.unsqueeze(1), 1)\n",
    "        # print(f'{gate_out_one_hot=}')\n",
    "\n",
    "        experts_out = torch.stack([expert(x) for expert in self.experts], dim=-1)\n",
    "        # print(f'{experts_out.shape=}')\n",
    "\n",
    "        out2 = experts_out[torch.arange(experts_out.size(0)), :, gate_out_max_idxs]\n",
    "        # print(f'{out2.shape=}')\n",
    "\n",
    "        # out = torch.sum(experts_out * gate_out.unsqueeze(1), dim=-1)\n",
    "        # print(f'{out.shape=}')\n",
    "        return out2\n",
    "\n",
    "seed = 69\n",
    "k_fold_dir_map = {\n",
    "    'Ga': '/home/mitlab/Documents/alxxtexxr/projects/classification_parkinsons_vgrf/datasets/preprocessed_mixed_loocv_v20240731_val_2/kfold10_window500_stride500_feature16_Ga2', # baseline\n",
    "    # 'Ga': '/home/mitlab/Documents/alxxtexxr/projects/classification_parkinsons_vgrf/datasets/preprocessed_mixed_loocv_v20240731_val_ 2/kfold10_window500_stride100_feature16_Ga2_3', # best\n",
    "    \n",
    "    'Ju': '/home/mitlab/Documents/alxxtexxr/projects/classification_parkinsons_vgrf/datasets/preprocessed_mixed_loocv_v20240731_val_2/kfold10_window500_stride500_feature16_Ju3', # baseline\n",
    "    \n",
    "    'Si': '/home/mitlab/Documents/alxxtexxr/projects/classification_parkinsons_vgrf/datasets/preprocessed_mixed_loocv_v20240731_val_2/kfold10_window500_stride250_feature16_Si8', # baseline\n",
    "    # 'Si': '/home/mitlab/Documents/alxxtexxr/projects/classification_parkinsons_vgrf/datasets/preprocessed_mixed_loocv_v20240731_val_2/kfold10_window500_stride100_feature16_Si8_2', # best\n",
    "}\n",
    "expert_model_dir_map = {\n",
    "    'Ga': '/home/mitlab/Documents/alxxtexxr/projects/classification_parkinsons_vgrf/outputs/train/RNNInceptionTime_Ga_baseline_20240911161249',\n",
    "    'Ju': '/home/mitlab/Documents/alxxtexxr/projects/classification_parkinsons_vgrf/outputs/train/RNNInceptionTime_Ju_baseline_20240911143621',\n",
    "    'Si': '/home/mitlab/Documents/alxxtexxr/projects/classification_parkinsons_vgrf/outputs/train/RNNInceptionTime_Si_baseline_20240911144140'\n",
    "}\n",
    "gate_model_dir = '/home/mitlab/Documents/alxxtexxr/projects/classification_parkinsons_vgrf/outputs/train/RNNInceptionTime_Gate_baseline_20240912075120'\n",
    "# moe_model_dir = '/home/mitlab/Documents/alxxtexxr/projects/classification_parkinsons_vgrf/outputs/train/RNNInceptionTime_MoE_baseline_20240912075120'\n",
    "k_fold = 10\n",
    "batch_size = 8\n",
    "n_feature = 16\n",
    "n_class = 4\n",
    "window_size = 500\n",
    "max_vgrf_data_len = 25_000\n",
    "device = 'cuda:0'\n",
    "\n",
    "os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed) \n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "# torch.use_deterministic_algorithms(True)\n",
    "\n",
    "moe_output = {\n",
    "    'acc': { 'folds': [], 'avg': None, 'std': None, },\n",
    "    'f1': { 'folds': [], 'avg': None, 'std': None, },\n",
    "    'precision': { 'folds': [], 'avg': None, 'std': None, },\n",
    "    'recall': { 'folds': [], 'avg': None, 'std': None, },\n",
    "    'cm': { 'folds': [], },\n",
    "    'val_loss': { 'folds': [], },\n",
    "}\n",
    "gate_output = {\n",
    "    'acc': { 'folds': [], 'avg': None, 'std': None, },\n",
    "    'f1': { 'folds': [], 'avg': None, 'std': None, },\n",
    "    'precision': { 'folds': [], 'avg': None, 'std': None, },\n",
    "    'recall': { 'folds': [], 'avg': None, 'std': None, },\n",
    "    'cm': { 'folds': [], },\n",
    "    'val_loss': { 'folds': [], },\n",
    "}\n",
    "expert_outputs = {\n",
    "    'Ga': {\n",
    "        'acc': { 'folds': [], 'avg': None, 'std': None, },\n",
    "        'f1': { 'folds': [], 'avg': None, 'std': None, },\n",
    "        'precision': { 'folds': [], 'avg': None, 'std': None, },\n",
    "        'recall': { 'folds': [], 'avg': None, 'std': None, },\n",
    "        'cm': { 'folds': [], },\n",
    "        'val_loss': { 'folds': [], },\n",
    "    },\n",
    "    'Ju': {\n",
    "        'acc': { 'folds': [], 'avg': None, 'std': None, },\n",
    "        'f1': { 'folds': [], 'avg': None, 'std': None, },\n",
    "        'precision': { 'folds': [], 'avg': None, 'std': None, },\n",
    "        'recall': { 'folds': [], 'avg': None, 'std': None, },\n",
    "        'cm': { 'folds': [], },\n",
    "        'val_loss': { 'folds': [], },\n",
    "    },\n",
    "    'Si': {\n",
    "        'acc': { 'folds': [], 'avg': None, 'std': None, },\n",
    "        'f1': { 'folds': [], 'avg': None, 'std': None, },\n",
    "        'precision': { 'folds': [], 'avg': None, 'std': None, },\n",
    "        'recall': { 'folds': [], 'avg': None, 'std': None, },\n",
    "        'cm': { 'folds': [], },\n",
    "        'val_loss': { 'folds': [], },\n",
    "    },\n",
    "}\n",
    "\n",
    "for i_fold in range(k_fold):\n",
    "    print_h(f\"FOLD-{i_fold+1}\", 128)\n",
    "\n",
    "    study_label_map = {\n",
    "        'Ga': 0,\n",
    "        'Ju': 1,\n",
    "        'Si': 2,\n",
    "    }\n",
    "    \n",
    "    expert_model_map = {\n",
    "        'Ga': RNNInceptionTime(c_in=n_feature, c_out=n_class, seq_len=window_size, bidirectional=True).to(device),\n",
    "        'Ju': RNNInceptionTime(c_in=n_feature, c_out=n_class, seq_len=window_size, bidirectional=True).to(device),\n",
    "        'Si': RNNInceptionTime(c_in=n_feature, c_out=n_class, seq_len=window_size, bidirectional=True).to(device),\n",
    "    }\n",
    "\n",
    "    X_train_window_GaJuSi = torch.empty(0, window_size, n_feature).float()\n",
    "    y_train_window_GaJuSi = torch.empty(0).long()\n",
    "    study_labels_train_window_GaJuSi = torch.empty(0).long()\n",
    "    \n",
    "    X_val_window_GaJuSi = torch.empty(0, window_size, n_feature).float()\n",
    "    y_val_window_GaJuSi = torch.empty(0).long()\n",
    "    study_labels_val_window_GaJuSi = torch.empty(0).long()\n",
    "\n",
    "    X_test_window_GaJuSi = torch.empty(0, window_size, n_feature).float()\n",
    "    y_test_window_GaJuSi = torch.empty(0).long()\n",
    "    study_labels_test_window_GaJuSi = torch.empty(0).long()\n",
    "\n",
    "    X_val_person_GaJuSi = torch.empty(0, max_vgrf_data_len, n_feature).float()\n",
    "    y_val_person_GaJuSi = torch.empty(0).long()\n",
    "    # study_labels_val_person_GaJuSi = torch.empty(0).long()\n",
    "\n",
    "    X_test_person_GaJuSi = torch.empty(0, max_vgrf_data_len, n_feature).float()\n",
    "    y_test_person_GaJuSi = torch.empty(0).long()\n",
    "    # study_labels_test_person_GaJuSi = torch.empty(0).long()\n",
    "\n",
    "    for study, k_fold_dir in k_fold_dir_map.items():\n",
    "        fold_i_dir_name = os.listdir(k_fold_dir)[i_fold]\n",
    "        fold_i_dir = os.path.join(k_fold_dir, fold_i_dir_name)\n",
    "\n",
    "        X_train_window = torch.tensor(np.load(os.path.join(fold_i_dir, f'X_train_window.npy'))).float()\n",
    "        y_train_window = torch.tensor(np.load(os.path.join(fold_i_dir, f'y_train_window.npy'))).long()\n",
    "        study_labels_train_window = torch.tensor([study_label_map[study]] * len(y_train_window)).long()\n",
    "        X_train_window_GaJuSi = torch.cat((X_train_window_GaJuSi, X_train_window), dim=0)\n",
    "        y_train_window_GaJuSi = torch.cat((y_train_window_GaJuSi, y_train_window), dim=0)\n",
    "        study_labels_train_window_GaJuSi = torch.cat((study_labels_train_window_GaJuSi, study_labels_train_window), dim=0)\n",
    "\n",
    "        X_val_window = torch.tensor(np.load(os.path.join(fold_i_dir, f'X_val_window.npy'))).float()\n",
    "        y_val_window = torch.tensor(np.load(os.path.join(fold_i_dir, f'y_val_window.npy'))).long()\n",
    "        study_labels_val_window = torch.tensor([study_label_map[study]] * len(y_val_window)).long()\n",
    "        X_val_window_GaJuSi = torch.cat((X_val_window_GaJuSi, X_val_window), dim=0)\n",
    "        y_val_window_GaJuSi = torch.cat((y_val_window_GaJuSi, y_val_window), dim=0)\n",
    "        study_labels_val_window_GaJuSi = torch.cat((study_labels_val_window_GaJuSi, study_labels_val_window), dim=0)\n",
    "\n",
    "        X_test_window = torch.tensor(np.load(os.path.join(fold_i_dir, f'X_test_window.npy'))).float()\n",
    "        y_test_window = torch.tensor(np.load(os.path.join(fold_i_dir, f'y_test_window.npy'))).long()\n",
    "        study_labels_test_window = torch.tensor([study_label_map[study]] * len(y_test_window)).long()\n",
    "        X_test_window_GaJuSi = torch.cat((X_test_window_GaJuSi, X_test_window), dim=0)\n",
    "        y_test_window_GaJuSi = torch.cat((y_test_window_GaJuSi, y_test_window), dim=0)\n",
    "        study_labels_test_window_GaJuSi = torch.cat((study_labels_test_window_GaJuSi, study_labels_test_window), dim=0)\n",
    "\n",
    "        X_val_person = torch.tensor(np.load(os.path.join(fold_i_dir, f'X_val_person.npy'))).float()\n",
    "        y_val_person = torch.tensor(np.load(os.path.join(fold_i_dir, f'y_val_person.npy'))).long()\n",
    "        X_val_person_GaJuSi = torch.cat((X_val_person_GaJuSi, X_val_person), dim=0)\n",
    "        y_val_person_GaJuSi = torch.cat((y_val_person_GaJuSi, y_val_person), dim=0)\n",
    "\n",
    "        X_test_person = torch.tensor(np.load(os.path.join(fold_i_dir, f'X_test_person.npy'))).float()\n",
    "        y_test_person = torch.tensor(np.load(os.path.join(fold_i_dir, f'y_test_person.npy'))).long()\n",
    "        X_test_person_GaJuSi = torch.cat((X_test_person_GaJuSi, X_test_person), dim=0)\n",
    "        y_test_person_GaJuSi = torch.cat((y_test_person_GaJuSi, y_test_person), dim=0)\n",
    "\n",
    "        train_window_dataset = TensorDataset(X_train_window, y_train_window)\n",
    "        val_window_dataset = TensorDataset(X_val_window, y_val_window)\n",
    "        test_window_dataset = TensorDataset(X_test_window, y_test_window)\n",
    "        \n",
    "        val_person_dataset = TensorDataset(X_val_person, y_val_person)\n",
    "        test_person_dataset = TensorDataset(X_test_person, y_test_person)\n",
    "\n",
    "        train_dataloader = DataLoader(train_window_dataset, batch_size=batch_size, shuffle=True)\n",
    "        val_dataloader = DataLoader(val_window_dataset, batch_size=batch_size, shuffle=False)\n",
    "        test_dataloader = DataLoader(test_window_dataset, batch_size=batch_size, shuffle=False)\n",
    "        \n",
    "        expert_model = expert_model_map[study]\n",
    "\n",
    "        # Load pretrained model\n",
    "        expert_model_dir = expert_model_dir_map[study]\n",
    "        expert_model_i_name = os.listdir(expert_model_dir)[i_fold]\n",
    "        expert_model_i_path = os.path.join(expert_model_dir, expert_model_i_name)\n",
    "        expert_model.load_state_dict(torch.load(expert_model_i_path))\n",
    "\n",
    "        print_h(\"EVALUATION ON PERSON DATA BY MAJORITY VOTING\", 64)\n",
    "        _, acc_person_majority_voting, f1_person_majority_voting, precision_person_majority_voting, recall_person_majority_voting, cm_person_majority_voting = eval_person_majority_voting(expert_model, val_person_dataset, criterion=None, average='weighted',\n",
    "                                                                                                                                                                                                window_size=window_size, debug=False)\n",
    "        print(\"acc:\", acc_person_majority_voting)\n",
    "        print(\"f1:\", f1_person_majority_voting)\n",
    "        print(\"precision:\", precision_person_majority_voting)\n",
    "        print(\"recall:\", recall_person_majority_voting)\n",
    "        print(\"cm:\\n\", np.array(cm_person_majority_voting))\n",
    "        print()\n",
    "\n",
    "        expert_outputs[study] = update_output(expert_outputs[study], {\n",
    "            'acc': acc_person_majority_voting,\n",
    "            'f1': f1_person_majority_voting,\n",
    "            'precision': precision_person_majority_voting,\n",
    "            'recall': recall_person_majority_voting,\n",
    "            'cm': cm_person_majority_voting,\n",
    "        })\n",
    "\n",
    "    print_h(\"GATE\", 96)\n",
    "\n",
    "    # train_window_dataset_GaJuSi = TensorDataset(X_train_window_GaJuSi, y_train_window_GaJuSi)\n",
    "    # val_window_dataset_GaJuSi = TensorDataset(X_val_window_GaJuSi, y_val_window_GaJuSi)\n",
    "    # test_window_dataset_GaJuSi = TensorDataset(X_test_window_GaJuSi, y_test_window_GaJuSi)\n",
    "\n",
    "    train_window_dataset_GaJuSi = TensorDataset(X_train_window_GaJuSi, study_labels_train_window_GaJuSi)\n",
    "    val_window_dataset_GaJuSi = TensorDataset(X_val_window_GaJuSi, study_labels_val_window_GaJuSi)\n",
    "    test_window_dataset_GaJuSi = TensorDataset(X_test_window_GaJuSi, study_labels_test_window_GaJuSi)\n",
    "\n",
    "    train_dataloader_GaJuSi = DataLoader(train_window_dataset_GaJuSi, batch_size=batch_size, shuffle=True)\n",
    "    val_dataloader_GaJuSi = DataLoader(val_window_dataset_GaJuSi, batch_size=batch_size, shuffle=False)\n",
    "    test_dataloader_GaJuSi = DataLoader(test_window_dataset_GaJuSi, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    gate_model = RNNInceptionTime(c_in=n_feature, c_out=len(study_label_map.keys()), seq_len=window_size, bidirectional=True).to(device)\n",
    "\n",
    "    # Load pretrained model\n",
    "    gate_model_i_name = os.listdir(gate_model_dir)[i_fold]\n",
    "    gate_model_i_path = os.path.join(gate_model_dir, gate_model_i_name)\n",
    "    gate_model.load_state_dict(torch.load(gate_model_i_path))\n",
    "\n",
    "    print_h(\"EVALUATION ON WINDOW DATA\", 64)\n",
    "    \n",
    "    _, acc_window, f1_window, precision_window, recall_window, cm_window = eval_window(gate_model, test_dataloader_GaJuSi, average='weighted')\n",
    "\n",
    "    print(\"acc:\", acc_window)\n",
    "    print(\"f1:\", f1_window)\n",
    "    print(\"precision:\", precision_window)\n",
    "    print(\"recall:\", recall_window)\n",
    "    print(\"cm:\\n\", np.array(cm_window))\n",
    "    print()\n",
    "\n",
    "    gate_output = update_output(gate_output, {\n",
    "        'acc': acc_window,\n",
    "        'f1': f1_window,\n",
    "        'precision': precision_window,\n",
    "        'recall': recall_window,\n",
    "        'cm': cm_window,\n",
    "    })\n",
    "\n",
    "    print_h(\"MoE\", 96)\n",
    "\n",
    "    val_person_dataset_GaJuSi = TensorDataset(X_val_person_GaJuSi, y_val_person_GaJuSi)\n",
    "    test_person_dataset_GaJuSi = TensorDataset(X_test_person_GaJuSi, y_test_person_GaJuSi)\n",
    "\n",
    "    moe_model = MoE(experts=expert_model_map.values(), gate=gate_model)\n",
    "\n",
    "    print_h(\"EVALUATION ON PERSON DATA BY MAJORITY VOTING\", 64)\n",
    "    _, acc_person_majority_voting, f1_person_majority_voting, precision_person_majority_voting, recall_person_majority_voting, cm_person_majority_voting = eval_person_majority_voting(moe_model, val_person_dataset_GaJuSi, criterion=None, average='weighted',\n",
    "                                                                                                                                                                                        window_size=window_size, debug=False)\n",
    "    print(\"acc:\", acc_person_majority_voting)\n",
    "    print(\"f1:\", f1_person_majority_voting)\n",
    "    print(\"precision:\", precision_person_majority_voting)\n",
    "    print(\"recall:\", recall_person_majority_voting)\n",
    "    print(\"cm:\\n\", np.array(cm_person_majority_voting))\n",
    "    print()\n",
    "\n",
    "    moe_output = update_output(moe_output, {\n",
    "        'acc': acc_person_majority_voting,\n",
    "        'f1': f1_person_majority_voting,\n",
    "        'precision': precision_person_majority_voting,\n",
    "        'recall': recall_person_majority_voting,\n",
    "        'cm': cm_person_majority_voting,\n",
    "    })\n",
    "\n",
    "    # for metric in ['acc', 'f1', 'precision', 'recall', 'cm']:\n",
    "    #     moe_output[metric]['folds'] += [moe_eval_output[metric]]\n",
    "    #     if metric != 'cm':\n",
    "    #         moe_output[metric]['avg'] = np.mean(moe_output[metric]['folds'])\n",
    "    #         moe_output[metric]['std'] = np.std(moe_output[metric]['folds'])\n",
    "    \n",
    "    # output['window']['train_loss']['folds'].append(global_train_loss_list)\n",
    "    # output['window']['val_loss']['folds'].append(global_val_loss_window_list)\n",
    "\n",
    "    # break # Test for only 1 fold"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
