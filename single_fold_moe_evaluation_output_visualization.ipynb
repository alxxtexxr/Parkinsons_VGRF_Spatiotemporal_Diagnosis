{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from pprint import pprint\n",
    "\n",
    "from src.utils import (\n",
    "    # Old utils\n",
    "    print_h, eval_window, eval_person_majority_voting,\n",
    "\n",
    "    # New utils\n",
    "    set_seed, get_device, init_model, init_metrics, update_metrics, save_metrics_to_json,\n",
    "    plot_k_fold_roc_curves_multiclass_v2, plot_k_fold_cm,\n",
    ")\n",
    "from src.models import HardMoE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random seed: 69\n",
      "Device: cuda\n",
      "Expert model name: RNNInceptionTime\n",
      "Expert model bidirectional: True\n",
      "Fold number: 6\n",
      "Gate model name tag: RNNInceptionTimeGate_bidirectional\n",
      "Gate model name: RNNInceptionTime\n",
      "Gate model bidirectional: True\n",
      "MoE model name tag: RNNInceptionTimeMoE_bidirectional\n",
      "Evaluation directory: evaluations/RNNInceptionTimeMoE_bidirectional_Ga_k10_w500_s500_Ju_k10_w500_s500_w_anomaly_Si_k10_w500_s250_w_anomaly_e100\n",
      "Evaluation output visualization save directory: evaluations/RNNInceptionTimeMoE_bidirectional_Ga_k10_w500_s500_Ju_k10_w500_s500_w_anomaly_Si_k10_w500_s250_w_anomaly_e100/out_viz\n"
     ]
    }
   ],
   "source": [
    "# Project config\n",
    "seed = 69\n",
    "set_seed(seed)\n",
    "device = get_device()\n",
    "print(\"Device:\", device)\n",
    "\n",
    "# Model config\n",
    "expert_model_path_map = {\n",
    "    # Default: RNN-InceptionTime\n",
    "    'Ga': 'checkpoints/RNNInceptionTime_bidirectional_Ga_k10_w500_s500_e20_v20250520224322/fold_06.pth',\n",
    "    'Ju': 'checkpoints/RNNInceptionTime_bidirectional_Ju_k10_w500_s500_w_anomaly_e5_v20250529001340/fold_06.pth',\n",
    "    'Si': 'checkpoints/RNNInceptionTime_bidirectional_Si_k10_w500_s250_w_anomaly_e30_v20250529213629/fold_06.pth',\n",
    "\n",
    "    # RNN\n",
    "    # 'Ga': 'checkpoints/RNN_bidirectional_Ga_k10_w500_s500_fold_06_e20_v20250603125917/fold_06.pth',\n",
    "    # 'Ju': 'checkpoints/RNN_bidirectional_Ju_k10_w500_s500_w_anomaly_fold_06_e5_v20250603130151/fold_06.pth',\n",
    "    # 'Si': 'checkpoints/RNN_bidirectional_Si_k10_w500_s250_w_anomaly_fold_06_e30_v20250603130328/fold_06.pth',\n",
    "\n",
    "    # InceptionTime\n",
    "    # 'Ga': 'checkpoints/InceptionTime_Ga_k10_w500_s500_fold_06_e20_v20250603130439/fold_06.pth',\n",
    "    # 'Ju': 'checkpoints/InceptionTime_Ju_k10_w500_s500_w_anomaly_fold_06_e5_v20250603130518/fold_06.pth',\n",
    "    # 'Si': 'checkpoints/InceptionTime_Si_k10_w500_s250_w_anomaly_fold_06_e30_v20250603130612/fold_06.pth',\n",
    "}\n",
    "\n",
    "# Get model names and parameters\n",
    "expert_names = [expert_model_dir.split('/')[-2].split('_'+study)[0] for study, expert_model_dir in expert_model_path_map.items()]\n",
    "assert len(set(expert_names)) == 1, f\"Expert model names are inconsistent: {expert_names}\"\n",
    "expert_name = expert_names[0]\n",
    "if 'bidirectional' in expert_name:\n",
    "    expert_name = expert_name.replace('_bidirectional', '')\n",
    "    expert_bidirectional = True\n",
    "else:\n",
    "    expert_bidirectional = False\n",
    "print(\"Expert model name:\", expert_name)\n",
    "print(\"Expert model bidirectional:\", expert_bidirectional)\n",
    "\n",
    "gate_model_path = 'checkpoints/RNNInceptionTimeGate_bidirectional_Ga_k10_w500_s500_Ju_k10_w500_s500_w_anomaly_Si_k10_w500_s250_w_anomaly_e20_v20250531134835/fold_06.pth' # Default: RNN-InceptionTime\n",
    "# gate_model_path = 'checkpoints/MLPGate_l2_Ga_k10_w500_s500_Ju_k10_w500_s500_w_anomaly_Si_k10_w500_s250_w_anomaly_fold_06_e20_v20250602215409/fold_06.pth' # MLP\n",
    "# gate_model_path = 'checkpoints/RNNGate_bidirectional_Ga_k10_w500_s500_Ju_k10_w500_s500_w_anomaly_Si_k10_w500_s250_w_anomaly_fold_06_e20_v20250603131259/fold_06.pth' # RNN\n",
    "# gate_model_path = 'checkpoints/InceptionTimeGate_Ga_k10_w500_s500_Ju_k10_w500_s500_w_anomaly_Si_k10_w500_s250_w_anomaly_fold_06_e20_v20250603131830/fold_06.pth' # InceptionTime\n",
    "\n",
    "gate_layers = [500, 500]\n",
    "gate_ps = [0.1, 0.2]\n",
    "\n",
    "# Data config\n",
    "fold_i_dir_map = {\n",
    "    'Ga': f'data/preprocessed/Ga_k10_w500_s500_v20250501004633/fold_06',\n",
    "    'Ju': f'data/preprocessed/Ju_k10_w500_s500_w_anomaly_v20250501004735/fold_06',\n",
    "    'Si': f'data/preprocessed/Si_k10_w500_s250_w_anomaly_v20250501004847/fold_06',\n",
    "}\n",
    "\n",
    "# Get fold number\n",
    "i_folds_data = [int(fold_i_dir.split('fold_')[-1]) for fold_i_dir in fold_i_dir_map.values()]\n",
    "i_folds_checkpoints = [int(expert_model_path.split('fold_')[-1].replace('.pth', '')) for expert_model_path in expert_model_path_map.values()]\n",
    "i_folds = i_folds_data + i_folds_checkpoints\n",
    "assert len(set(i_folds)) == 1, f\"Fold numbers are inconsistent: {({'data': i_folds_data, 'checkpoints': i_folds_checkpoints})}\"\n",
    "i_fold = i_folds[0]\n",
    "print(\"Fold number:\", i_fold)\n",
    "\n",
    "# Evaluation config\n",
    "k_fold = 10\n",
    "batch_size = 8\n",
    "n_feat = 16\n",
    "n_class = 4\n",
    "window_size = 500\n",
    "max_vgrf_data_len = 25_000\n",
    "\n",
    "gate_name_tag = gate_model_path.rsplit('/')[-2].split('_Ga')[0]\n",
    "gate_name = gate_name_tag.split('Gate')[0]\n",
    "gate_bidirectional = 'bidirectional' in gate_name_tag\n",
    "print(\"Gate model name tag:\", gate_name_tag)\n",
    "print(\"Gate model name:\", gate_name)\n",
    "print(\"Gate model bidirectional:\", gate_bidirectional)\n",
    "\n",
    "moe_name_tag = f'{expert_name}MoE{'_bidirectional' if expert_bidirectional else ''}{f'_{gate_name_tag}' if gate_name != expert_name else ''}'\n",
    "print(\"MoE model name tag:\", moe_name_tag)\n",
    "\n",
    "eval_dir = 'evaluations/' + moe_name_tag + gate_model_path.rsplit(gate_name_tag)[-1].split('_v')[0]\n",
    "out_viz_dir = eval_dir + '/out_viz'\n",
    "\n",
    "print(\"Evaluation directory:\", eval_dir)\n",
    "print(\"Evaluation output visualization save directory:\", out_viz_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "study_label_map = {\n",
    "    'Ga': 0,\n",
    "    'Ju': 1,\n",
    "    'Si': 2,\n",
    "}\n",
    "\n",
    "print_h(f\"FOLD {i_fold}\", 128)\n",
    "\n",
    "expert_model_map = {\n",
    "    'Ga': init_model(expert_name, device, c_in=n_feat, c_out=n_class, seq_len=window_size, bidirectional=expert_bidirectional),\n",
    "    'Ju': init_model(expert_name, device, c_in=n_feat, c_out=n_class, seq_len=window_size, bidirectional=expert_bidirectional),\n",
    "    'Si': init_model(expert_name, device, c_in=n_feat, c_out=n_class, seq_len=window_size, bidirectional=expert_bidirectional),\n",
    "}\n",
    "\n",
    "X_train_window_GaJuSi = torch.empty(0, window_size, n_feat).float()\n",
    "y_train_window_GaJuSi = torch.empty(0).long()\n",
    "study_labels_train_window_GaJuSi = torch.empty(0).long()\n",
    "\n",
    "X_val_window_GaJuSi = torch.empty(0, window_size, n_feat).float()\n",
    "y_val_window_GaJuSi = torch.empty(0).long()\n",
    "study_labels_val_window_GaJuSi = torch.empty(0).long()\n",
    "\n",
    "X_test_window_GaJuSi = torch.empty(0, window_size, n_feat).float()\n",
    "y_test_window_GaJuSi = torch.empty(0).long()\n",
    "study_labels_test_window_GaJuSi = torch.empty(0).long()\n",
    "\n",
    "X_val_person_GaJuSi = torch.empty(0, max_vgrf_data_len, n_feat).float()\n",
    "y_val_person_GaJuSi = torch.empty(0).long()\n",
    "# study_labels_val_person_GaJuSi = torch.empty(0).long()\n",
    "\n",
    "X_test_person_GaJuSi = torch.empty(0, max_vgrf_data_len, n_feat).float()\n",
    "y_test_person_GaJuSi = torch.empty(0).long()\n",
    "# study_labels_test_person_GaJuSi = torch.empty(0).long()\n",
    "\n",
    "for study, fold_i_dir in fold_i_dir_map.items():\n",
    "    # ================================================================================================\n",
    "    # DATA\n",
    "    # ================================================================================================\n",
    "    X_train_window = torch.tensor(np.load(os.path.join(fold_i_dir, f'X_train_window.npy'))).float()\n",
    "    y_train_window = torch.tensor(np.load(os.path.join(fold_i_dir, f'y_train_window.npy'))).long()\n",
    "    study_labels_train_window = torch.tensor([study_label_map[study]] * len(y_train_window)).long()\n",
    "    X_train_window_GaJuSi = torch.cat((X_train_window_GaJuSi, X_train_window), dim=0)\n",
    "    y_train_window_GaJuSi = torch.cat((y_train_window_GaJuSi, y_train_window), dim=0)\n",
    "    study_labels_train_window_GaJuSi = torch.cat((study_labels_train_window_GaJuSi, study_labels_train_window), dim=0)\n",
    "\n",
    "    X_val_window = torch.tensor(np.load(os.path.join(fold_i_dir, f'X_val_window.npy'))).float()\n",
    "    y_val_window = torch.tensor(np.load(os.path.join(fold_i_dir, f'y_val_window.npy'))).long()\n",
    "    study_labels_val_window = torch.tensor([study_label_map[study]] * len(y_val_window)).long()\n",
    "    X_val_window_GaJuSi = torch.cat((X_val_window_GaJuSi, X_val_window), dim=0)\n",
    "    y_val_window_GaJuSi = torch.cat((y_val_window_GaJuSi, y_val_window), dim=0)\n",
    "    study_labels_val_window_GaJuSi = torch.cat((study_labels_val_window_GaJuSi, study_labels_val_window), dim=0)\n",
    "\n",
    "    X_test_window = torch.tensor(np.load(os.path.join(fold_i_dir, f'X_test_window.npy'))).float()\n",
    "    y_test_window = torch.tensor(np.load(os.path.join(fold_i_dir, f'y_test_window.npy'))).long()\n",
    "    study_labels_test_window = torch.tensor([study_label_map[study]] * len(y_test_window)).long()\n",
    "    X_test_window_GaJuSi = torch.cat((X_test_window_GaJuSi, X_test_window), dim=0)\n",
    "    y_test_window_GaJuSi = torch.cat((y_test_window_GaJuSi, y_test_window), dim=0)\n",
    "    study_labels_test_window_GaJuSi = torch.cat((study_labels_test_window_GaJuSi, study_labels_test_window), dim=0)\n",
    "\n",
    "    X_val_person = torch.tensor(np.load(os.path.join(fold_i_dir, f'X_val_person.npy'))).float()\n",
    "    y_val_person = torch.tensor(np.load(os.path.join(fold_i_dir, f'y_val_person.npy'))).long()\n",
    "    X_val_person_GaJuSi = torch.cat((X_val_person_GaJuSi, X_val_person), dim=0)\n",
    "    y_val_person_GaJuSi = torch.cat((y_val_person_GaJuSi, y_val_person), dim=0)\n",
    "\n",
    "    X_test_person = torch.tensor(np.load(os.path.join(fold_i_dir, f'X_test_person.npy'))).float()\n",
    "    y_test_person = torch.tensor(np.load(os.path.join(fold_i_dir, f'y_test_person.npy'))).long()\n",
    "    X_test_person_GaJuSi = torch.cat((X_test_person_GaJuSi, X_test_person), dim=0)\n",
    "    y_test_person_GaJuSi = torch.cat((y_test_person_GaJuSi, y_test_person), dim=0)\n",
    "\n",
    "    train_window_dataset = TensorDataset(X_train_window, y_train_window)\n",
    "    val_window_dataset = TensorDataset(X_val_window, y_val_window)\n",
    "    test_window_dataset = TensorDataset(X_test_window, y_test_window)\n",
    "    \n",
    "    val_person_dataset = TensorDataset(X_val_person, y_val_person)\n",
    "    test_person_dataset = TensorDataset(X_test_person, y_test_person)\n",
    "\n",
    "    train_dataloader = DataLoader(train_window_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_dataloader = DataLoader(val_window_dataset, batch_size=batch_size, shuffle=False)\n",
    "    test_dataloader = DataLoader(test_window_dataset, batch_size=batch_size, shuffle=False)\n",
    "    \n",
    "    # ================================================================================================\n",
    "    # EXPERT MODEL\n",
    "    # ================================================================================================\n",
    "    expert_model = expert_model_map[study]\n",
    "    expert_model.load_state_dict(torch.load(expert_model_path_map[study], map_location=device))\n",
    "\n",
    "# ================================================================================================\n",
    "# GATE MODEL\n",
    "# ================================================================================================\n",
    "gate_model = init_model(gate_name, device, c_in=n_feat, c_out=len(study_label_map.keys()), seq_len=window_size, bidirectional=gate_bidirectional, layers=gate_layers, ps=gate_ps)\n",
    "gate_model.load_state_dict(torch.load(gate_model_path, map_location=device))\n",
    "\n",
    "# ================================================================================================\n",
    "# MoE MODEL\n",
    "# ================================================================================================\n",
    "moe_model = HardMoE(experts=expert_model_map.values(), gate=gate_model).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Output Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_dataset(X, y, study_labels, study, cls):\n",
    "    study_ = study\n",
    "    study = study_label_map[study_]\n",
    "    \n",
    "    mask = (y == cls) & (study_labels == study)\n",
    "    X_cls = X[mask]\n",
    "    y_cls = y[mask]\n",
    "    study_labels_cls = study_labels[mask]\n",
    "\n",
    "    if X_cls.shape[0] > 0:\n",
    "        idx_sample = torch.randint(0, X_cls.shape[0], (1,)).item()\n",
    "        X_sample = X_cls[idx_sample].unsqueeze(0)\n",
    "        y_sample = y_cls[idx_sample].item()\n",
    "        study_labels_sample = study_labels_cls[idx_sample].item()\n",
    "\n",
    "        assert cls == y_sample\n",
    "        assert study == study_labels_sample\n",
    "        \n",
    "        return X_sample, cls, study_\n",
    "    return None, cls, study_\n",
    "\n",
    "studies = study_label_map.keys()\n",
    "classes = list(range(n_class))\n",
    "study_cls_list = [study + '_' + str(cls) for cls in classes for study in studies]\n",
    "\n",
    "X_sample_map = {study_cls: sample_dataset(X_test_window_GaJuSi, y_test_window_GaJuSi, study_labels_test_window_GaJuSi, study=study_cls.split('_')[0], cls=int(study_cls.split('_')[-1]))[0] for study_cls in study_cls_list}\n",
    "\n",
    "# DEBUG: Sanity check\n",
    "for k, v in X_sample_map.items():\n",
    "    print(k, \"->\", v.shape if v != None else None)\n",
    "\n",
    "model_map = {\n",
    "    'gate': gate_model,\n",
    "    **expert_model_map,\n",
    "}\n",
    "output_map = {study_cls: {} for study_cls in X_sample_map.keys()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for study_cls, X_sample in X_sample_map.items():\n",
    "    if X_sample is None:\n",
    "        continue\n",
    "\n",
    "    print_h(study_cls)\n",
    "\n",
    "    for model_type in model_map.keys():\n",
    "        print_h((\"EXPERT-\" + model_type if len(model_type) == 2 else model_type.upper()) + \" MODEL\", 96)\n",
    "\n",
    "        # Register hooks\n",
    "        intermediate_outputs = {}\n",
    "\n",
    "        def get_output_hook(name):\n",
    "            def hook(module, input, output):\n",
    "                intermediate_outputs[name] = output.detach().cpu().numpy()\n",
    "            return hook\n",
    "\n",
    "        model_map[model_type].rnn_dropout.register_forward_hook(get_output_hook('rnn_output'))\n",
    "        model_map[model_type].gap.register_forward_hook(get_output_hook('gap'))\n",
    "        model_map[model_type].concat.register_forward_hook(get_output_hook('concat'))\n",
    "\n",
    "        # Forward pass\n",
    "        model_map[model_type].eval()\n",
    "        with torch.no_grad():\n",
    "            model_map[model_type](X_sample.permute(0, 2, 1).to(device))\n",
    "\n",
    "        print(\"RNN output:\", intermediate_outputs['rnn_output'].shape)\n",
    "        print(\"InceptionTime output:\", intermediate_outputs['gap'].shape)\n",
    "        print(\"Concatenated RNN-InceptionTime output:\", intermediate_outputs['concat'].shape)\n",
    "\n",
    "        # Store the `concat` output\n",
    "        output_map[study_cls][model_type] = intermediate_outputs['concat']\n",
    "\n",
    "        # TODO: Remove the hooks\n",
    "\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from matplotlib.colors import Normalize\n",
    "from matplotlib.cm import ScalarMappable\n",
    "\n",
    "def plot_output_heatmap(output_map, name, save_dir=None, plot=False):\n",
    "    # Create subplots\n",
    "    fig, axes = plt.subplots(len(output_map), 1, figsize=(16, 6))\n",
    "\n",
    "    for i, item in enumerate(output_map.items()):\n",
    "        model_type, output = item\n",
    "        output_norm = (output - output.min()) / (output.max() - output.min() + 1e-8)\n",
    "        sns.heatmap(output_norm, ax=axes[i], yticklabels=False, cmap='viridis', cbar=False)\n",
    "\n",
    "        # Add left-side \"title\" using ylabel\n",
    "        title = \"Expert - \" + model_type if len(model_type) == 2 else model_type.capitalize()\n",
    "        axes[i].set_ylabel(title, labelpad=11, va='center')\n",
    "\n",
    "        # Add border around the entire heatmap axes\n",
    "        for spine in axes[i].spines.values():\n",
    "            spine.set_visible(True)\n",
    "            spine.set_linewidth(1)\n",
    "            spine.set_edgecolor('black')\n",
    "\n",
    "    # Create a single colorbar axis on the right side\n",
    "    norm = Normalize(vmin=0, vmax=1)\n",
    "    sm = ScalarMappable(cmap='viridis', norm=norm)\n",
    "    sm.set_array([])\n",
    "    cbar_ax = fig.add_axes([0.92, 0.085, 0.01, 0.89]) # [left, bottom, width, height] in figure coords\n",
    "    cbar = fig.colorbar(sm, cax=cbar_ax)\n",
    "\n",
    "    # Remove the black border from the colorbar\n",
    "    cbar.outline.set_visible(False)\n",
    "\n",
    "    plt.tight_layout(rect=[0, 0, 0.91, 1]) # Leave space on the right for colorbar\n",
    "\n",
    "    if save_dir:\n",
    "        os.makedirs(save_dir, exist_ok=True)\n",
    "        save_path = os.path.join(save_dir, name + '.png')\n",
    "        plt.savefig(save_path)\n",
    "\n",
    "    if plot:\n",
    "        plt.show()\n",
    "\n",
    "    if save_dir:\n",
    "        print(\"Saved to:\", save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for study_cls, output_map_i in output_map.items():\n",
    "    if not output_map_i:\n",
    "        continue\n",
    "\n",
    "    print_h(study_cls)\n",
    "    plot_output_heatmap(output_map_i, name=study_cls, save_dir=out_viz_dir,  plot=False)\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "alxxtexxr_py312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
