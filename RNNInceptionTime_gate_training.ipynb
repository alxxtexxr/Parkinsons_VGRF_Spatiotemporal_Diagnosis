{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "from datetime import datetime\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "from src.utils import (\n",
    "    set_seed, get_device, print_h, \n",
    "    eval_window, eval_person_severity_voting, eval_person_majority_voting, eval_person_max_severity,\n",
    "    init_metrics, update_metrics, save_metrics_to_json,\n",
    ")\n",
    "from src.models import RNNInceptionTime, HardMoE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random seed: 69\n",
      "Device: mps\n",
      "K-fold: 10\n",
      "Run name tag: Ga_k10_w500_s500_Ju_k10_w500_s500_Si_k10_w500_s250_e20\n"
     ]
    }
   ],
   "source": [
    "seed = 69\n",
    "set_seed(seed)\n",
    "device = get_device()\n",
    "print(\"Device:\", device)\n",
    "\n",
    "# Data and model config\n",
    "k_fold_dir_map = {\n",
    "    'Ga': 'data/preprocessed/Ga_k10_w500_s500_v20250426211229',\n",
    "    'Ju': 'data/preprocessed/Ju_k10_w500_s500_v20250426211207',\n",
    "    'Si': 'data/preprocessed/Si_k10_w500_s250_v20250426211052',\n",
    "}\n",
    "model_dir_map = {\n",
    "    # 'Ga': 'checkpoints/RNNInceptionTime_Ga_k10_w500_s500_e5',\n",
    "    # 'Ju': 'checkpoints/RNNInceptionTime_Ju_k10_w500_s500_e30',\n",
    "    # 'Si': 'checkpoints/RNNInceptionTime_Si_k10_w500_s250_e10',\n",
    "\n",
    "    # TEST: Model directories for testing\n",
    "    'Ga': 'checkpoints/RNNInceptionTime_Ga_k10_w500_s500_e1_v20250430215415',\n",
    "    'Ju': 'checkpoints/RNNInceptionTime_Ju_k10_w500_s500_e1_v20250430220513',\n",
    "    'Si': 'checkpoints/RNNInceptionTime_Si_k10_w500_s250_e1_v20250430220736',\n",
    "}\n",
    "\n",
    "\n",
    "# Set up model path mapping and get number of folds (K-fold)\n",
    "model_path_map = {study: [model_dir_study+'/'+f for f in os.listdir(model_dir_study) if f.endswith('.pth')] \n",
    "                  for study, model_dir_study in model_dir_map.items()}\n",
    "assert len(set([len(model_path_study) for model_path_study in model_path_map.values()])) == 1, \\\n",
    "    f\"Inconsistent number of folds across dataset studies: {[len(v) for v in model_path_map.values()]}\"\n",
    "k_fold = len(list(model_path_map.values())[0])\n",
    "print(\"K-fold:\", k_fold)\n",
    "\n",
    "# Training config\n",
    "n_epoch = 20\n",
    "batch_size = 8\n",
    "k_fold = 10\n",
    "n_feat = 16\n",
    "n_class = 4\n",
    "window_size = 500\n",
    "max_vgrf_data_len = 25_000\n",
    "lr = 3e-4\n",
    "\n",
    "# Generate name tag\n",
    "run_name_tag = '_'.join([k_fold_dir.split('/')[-1].rsplit('_v', 1)[0] for k_fold_dir in k_fold_dir_map.values()]) + f'_e{n_epoch}'\n",
    "print(\"Run name tag:\", run_name_tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set run names\n",
    "v = datetime.now().strftime(\"%Y%m%d%H%M%S\")\n",
    "gate_run_name = f'RNNInceptionTime_gate_{run_name_tag+'_' if run_name_tag else ''}v{v}'\n",
    "moe_run_name = f'RNNInceptionTimeMoE_{run_name_tag+'_' if run_name_tag else ''}v{v}'\n",
    "print(\"Gate model run name:\", gate_run_name)\n",
    "print(\"MoE model run name:\", moe_run_name)\n",
    "print()\n",
    "\n",
    "# Create save directories\n",
    "gate_save_dir = 'checkpoints/' + gate_run_name\n",
    "moe_save_dir = 'checkpoints/' + moe_run_name\n",
    "os.makedirs(gate_save_dir, exist_ok=True)\n",
    "os.makedirs(moe_save_dir, exist_ok=True)\n",
    "print(\"Gate model save directory:\", gate_save_dir)\n",
    "print(\"MoE model save directory:\", moe_save_dir)\n",
    "print()\n",
    "\n",
    "# Initialize evaluation metrics\n",
    "gate_metrics = {\n",
    "    'window': init_metrics(['acc', 'f1', 'precision', 'recall', 'cm', 'train_loss', 'val_loss']),\n",
    "    # 'person_majority_voting': init_metrics(['acc', 'f1', 'precision', 'recall', 'cm', 'train_loss', 'val_loss']),\n",
    "    # 'person_severity_voting': init_metrics(['acc', 'f1', 'precision', 'recall', 'cm', 'train_loss', 'val_loss']),\n",
    "    # 'person_max_severity': init_metrics(['acc', 'f1', 'precision', 'recall', 'cm', 'train_loss', 'val_loss']),\n",
    "}\n",
    "moe_metrics = {\n",
    "    # 'window': init_metrics(['acc', 'f1', 'precision', 'recall', 'cm']),\n",
    "    'person_majority_voting': init_metrics(['acc', 'f1', 'precision', 'recall', 'cm']),\n",
    "    # 'person_severity_voting': init_metrics(['acc', 'f1', 'precision', 'recall', 'cm']),\n",
    "    # 'person_max_severity': init_metrics(['acc', 'f1', 'precision', 'recall', 'cm']),\n",
    "}\n",
    "\n",
    "study_label_map = {\n",
    "    'Ga': 0,\n",
    "    'Ju': 1,\n",
    "    'Si': 2,\n",
    "}\n",
    "for i_fold in range(k_fold):\n",
    "        # ================================================================================================================================\n",
    "        # FOLD\n",
    "        # ================================================================================================================================\n",
    "        print_h(f\"FOLD-{i_fold+1}\", 128)\n",
    "        \n",
    "        expert_model_map = {\n",
    "            'Ga': RNNInceptionTime(c_in=n_feat, c_out=n_class, seq_len=window_size, bidirectional=True).to(device),\n",
    "            'Ju': RNNInceptionTime(c_in=n_feat, c_out=n_class, seq_len=window_size, bidirectional=True).to(device),\n",
    "            'Si': RNNInceptionTime(c_in=n_feat, c_out=n_class, seq_len=window_size, bidirectional=True).to(device),\n",
    "        }\n",
    "\n",
    "        X_train_window_GaJuSi = torch.empty(0, window_size, n_feat).float()\n",
    "        y_train_window_GaJuSi = torch.empty(0).long()\n",
    "        study_labels_train_window_GaJuSi = torch.empty(0).long()\n",
    "        \n",
    "        X_val_window_GaJuSi = torch.empty(0, window_size, n_feat).float()\n",
    "        y_val_window_GaJuSi = torch.empty(0).long()\n",
    "        study_labels_val_window_GaJuSi = torch.empty(0).long()\n",
    "\n",
    "        X_test_window_GaJuSi = torch.empty(0, window_size, n_feat).float()\n",
    "        y_test_window_GaJuSi = torch.empty(0).long()\n",
    "        study_labels_test_window_GaJuSi = torch.empty(0).long()\n",
    "\n",
    "        X_val_person_GaJuSi = torch.empty(0, max_vgrf_data_len, n_feat).float()\n",
    "        y_val_person_GaJuSi = torch.empty(0).long()\n",
    "        # study_labels_val_person_GaJuSi = torch.empty(0).long()\n",
    "\n",
    "        X_test_person_GaJuSi = torch.empty(0, max_vgrf_data_len, n_feat).float()\n",
    "        y_test_person_GaJuSi = torch.empty(0).long()\n",
    "        # study_labels_test_person_GaJuSi = torch.empty(0).long()\n",
    "\n",
    "        for study, k_fold_dir in k_fold_dir_map.items():\n",
    "            # ================================================================================================\n",
    "            # EXPERT MODEL\n",
    "            # ================================================================================================\n",
    "            print_h(f\"EXPERT-{study} MODEL\", 96)\n",
    "            \n",
    "            fold_i_dir_name = os.listdir(k_fold_dir)[i_fold]\n",
    "            fold_i_dir = os.path.join(k_fold_dir, fold_i_dir_name)\n",
    "\n",
    "            X_train_window = torch.tensor(np.load(os.path.join(fold_i_dir, f'X_train_window.npy'))).float()\n",
    "            y_train_window = torch.tensor(np.load(os.path.join(fold_i_dir, f'y_train_window.npy'))).long()\n",
    "            study_labels_train_window = torch.tensor([study_label_map[study]] * len(y_train_window)).long()\n",
    "            X_train_window_GaJuSi = torch.cat((X_train_window_GaJuSi, X_train_window), dim=0)\n",
    "            y_train_window_GaJuSi = torch.cat((y_train_window_GaJuSi, y_train_window), dim=0)\n",
    "            study_labels_train_window_GaJuSi = torch.cat((study_labels_train_window_GaJuSi, study_labels_train_window), dim=0)\n",
    "\n",
    "            X_val_window = torch.tensor(np.load(os.path.join(fold_i_dir, f'X_val_window.npy'))).float()\n",
    "            y_val_window = torch.tensor(np.load(os.path.join(fold_i_dir, f'y_val_window.npy'))).long()\n",
    "            study_labels_val_window = torch.tensor([study_label_map[study]] * len(y_val_window)).long()\n",
    "            X_val_window_GaJuSi = torch.cat((X_val_window_GaJuSi, X_val_window), dim=0)\n",
    "            y_val_window_GaJuSi = torch.cat((y_val_window_GaJuSi, y_val_window), dim=0)\n",
    "            study_labels_val_window_GaJuSi = torch.cat((study_labels_val_window_GaJuSi, study_labels_val_window), dim=0)\n",
    "\n",
    "            X_test_window = torch.tensor(np.load(os.path.join(fold_i_dir, f'X_test_window.npy'))).float()\n",
    "            y_test_window = torch.tensor(np.load(os.path.join(fold_i_dir, f'y_test_window.npy'))).long()\n",
    "            study_labels_test_window = torch.tensor([study_label_map[study]] * len(y_test_window)).long()\n",
    "            X_test_window_GaJuSi = torch.cat((X_test_window_GaJuSi, X_test_window), dim=0)\n",
    "            y_test_window_GaJuSi = torch.cat((y_test_window_GaJuSi, y_test_window), dim=0)\n",
    "            study_labels_test_window_GaJuSi = torch.cat((study_labels_test_window_GaJuSi, study_labels_test_window), dim=0)\n",
    "\n",
    "            X_val_person = torch.tensor(np.load(os.path.join(fold_i_dir, f'X_val_person.npy'))).float()\n",
    "            y_val_person = torch.tensor(np.load(os.path.join(fold_i_dir, f'y_val_person.npy'))).long()\n",
    "            X_val_person_GaJuSi = torch.cat((X_val_person_GaJuSi, X_val_person), dim=0)\n",
    "            y_val_person_GaJuSi = torch.cat((y_val_person_GaJuSi, y_val_person), dim=0)\n",
    "\n",
    "            X_test_person = torch.tensor(np.load(os.path.join(fold_i_dir, f'X_test_person.npy'))).float()\n",
    "            y_test_person = torch.tensor(np.load(os.path.join(fold_i_dir, f'y_test_person.npy'))).long()\n",
    "            X_test_person_GaJuSi = torch.cat((X_test_person_GaJuSi, X_test_person), dim=0)\n",
    "            y_test_person_GaJuSi = torch.cat((y_test_person_GaJuSi, y_test_person), dim=0)\n",
    "\n",
    "            train_window_dataset = TensorDataset(X_train_window, y_train_window)\n",
    "            val_window_dataset = TensorDataset(X_val_window, y_val_window)\n",
    "            test_window_dataset = TensorDataset(X_test_window, y_test_window)\n",
    "            \n",
    "            val_person_dataset = TensorDataset(X_val_person, y_val_person)\n",
    "            test_person_dataset = TensorDataset(X_test_person, y_test_person)\n",
    "\n",
    "            train_dataloader = DataLoader(train_window_dataset, batch_size=batch_size, shuffle=True)\n",
    "            val_dataloader = DataLoader(val_window_dataset, batch_size=batch_size, shuffle=False)\n",
    "            test_dataloader = DataLoader(test_window_dataset, batch_size=batch_size, shuffle=False)\n",
    "            \n",
    "            expert_model = expert_model_map[study]\n",
    "\n",
    "            # Load pretrained model\n",
    "            model_i_path = model_path_map[study][i_fold]\n",
    "            expert_model.load_state_dict(torch.load(model_i_path, map_location=device))\n",
    "        \n",
    "            # ================================================================\n",
    "            # EXPERT MODEL EVALUATION ON PERSON DATA BY MAJORITY VOTING\n",
    "            # ================================================================\n",
    "            print_h(\"EVALUATION ON PERSON DATA BY MAJORITY VOTING\", 64)\n",
    "            _, acc_person_majority_voting, f1_person_majority_voting, precision_person_majority_voting, recall_person_majority_voting, cm_person_majority_voting, *_ = eval_person_majority_voting(expert_model, val_person_dataset, criterion=None, average='weighted',\n",
    "                                                                                                                                                                                                    window_size=window_size, debug=False)\n",
    "            print(\"acc:\", acc_person_majority_voting)\n",
    "            print(\"f1:\", f1_person_majority_voting)\n",
    "            print(\"precision:\", precision_person_majority_voting)\n",
    "            print(\"recall:\", recall_person_majority_voting)\n",
    "            print(\"cm:\\n\", np.array(cm_person_majority_voting))\n",
    "            print()\n",
    "\n",
    "        # ================================================================================================\n",
    "        # GATE MODEL\n",
    "        # ================================================================================================\n",
    "        print_h(\"GATE MODEL\", 96)\n",
    "\n",
    "        # train_window_dataset_GaJuSi = TensorDataset(X_train_window_GaJuSi, y_train_window_GaJuSi)\n",
    "        # val_window_dataset_GaJuSi = TensorDataset(X_val_window_GaJuSi, y_val_window_GaJuSi)\n",
    "        # test_window_dataset_GaJuSi = TensorDataset(X_test_window_GaJuSi, y_test_window_GaJuSi)\n",
    "\n",
    "        train_window_dataset_GaJuSi = TensorDataset(X_train_window_GaJuSi, study_labels_train_window_GaJuSi)\n",
    "        val_window_dataset_GaJuSi = TensorDataset(X_val_window_GaJuSi, study_labels_val_window_GaJuSi)\n",
    "        test_window_dataset_GaJuSi = TensorDataset(X_test_window_GaJuSi, study_labels_test_window_GaJuSi)\n",
    "\n",
    "        train_dataloader_GaJuSi = DataLoader(train_window_dataset_GaJuSi, batch_size=batch_size, shuffle=True)\n",
    "        val_dataloader_GaJuSi = DataLoader(val_window_dataset_GaJuSi, batch_size=batch_size, shuffle=False)\n",
    "        test_dataloader_GaJuSi = DataLoader(test_window_dataset_GaJuSi, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "        # ================================================================\n",
    "        # GATE MODEL TRAINING\n",
    "        # ================================================================\n",
    "        print_h(\"TRAINING\", 64)\n",
    "        gate_model = RNNInceptionTime(c_in=n_feat, c_out=len(study_label_map.keys()), seq_len=window_size, bidirectional=True).to(device)\n",
    "\n",
    "        # Initialize optimizer and loss function\n",
    "        optimizer = torch.optim.Adam(gate_model.parameters(), lr=lr)\n",
    "        criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "        # Swith the model to training mode\n",
    "        gate_model.train()\n",
    "        \n",
    "        # Loop training epochs\n",
    "        global_val_loss_window_list = []\n",
    "        global_val_loss_person_list = []\n",
    "        global_train_loss_list = []\n",
    "        train_loss_list = []\n",
    "        # step = 0\n",
    "        for epoch in range(n_epoch):\n",
    "            # Loop training batches\n",
    "            for iter, (X_train, y_train) in enumerate(train_dataloader_GaJuSi):\n",
    "                # Flush the computed gradients\n",
    "                optimizer.zero_grad()\n",
    "                \n",
    "                X_train = X_train.to(device)\n",
    "                y_train = y_train.to(device)\n",
    "                \n",
    "                # Feed forward the model\n",
    "                X_train = X_train.permute(0, 2, 1)\n",
    "                y_pred = gate_model(X_train)\n",
    "\n",
    "                # print(f'{X_train=}')\n",
    "                # print(f'{y_pred=}')\n",
    "                \n",
    "                # Compute training loss\n",
    "                train_loss = criterion(y_pred, y_train)\n",
    "                train_loss_list.append(train_loss)\n",
    "                \n",
    "                # if (iter+1) % 'step_siz']= 0:\n",
    "                if iter+1 == len(train_dataloader_GaJuSi):\n",
    "                    # ================================\n",
    "                    # GATE MODEL VALIDATION\n",
    "                    # ================================\n",
    "                    avg_val_loss_window, acc_window, f1_window, _, _, _ = eval_window(gate_model, val_dataloader_GaJuSi, criterion, average='weighted')\n",
    "                    # avg_val_loss_person, acc_person, f1_person, _, _, _ = eval_person_majority_voting(model, test_person_dataset_GaJuSi, criterion=criterion, average='weighted',\n",
    "                    #                                                                                   window_size=window_size, zeros_filter_thres=zeros_filter_thres)\n",
    "                    \n",
    "                    global_val_loss_window_list.append(avg_val_loss_window)\n",
    "                    # global_val_loss_person_list.append(avg_val_loss_person)\n",
    "                    \n",
    "                    # Compute the average training loss for each epoch\n",
    "                    avg_train_loss = sum(train_loss_list) / len(train_dataloader)\n",
    "                    global_train_loss_list.append(avg_train_loss.item())\n",
    "                    train_loss_list = []\n",
    "                    \n",
    "                    # ================================\n",
    "                    # GATE MODEL LOGGING\n",
    "                    # ================================\n",
    "                    print(f\"epoch: {epoch+1}, \"\n",
    "                        # f\"iter: {iter+1}, \"\n",
    "                        # f\"step: {step+1}, \"\n",
    "                        f\"train/loss: {avg_train_loss:.3f}, \"\n",
    "                        f\"val/loss_window: {avg_val_loss_window:.3f}, \"\n",
    "                        f\"val/acc_window: {acc_window:.3f}, \"\n",
    "                        f\"val/f1_window: {f1_window:.3f}, \"\n",
    "                        # f\"val/loss_person: {avg_val_loss_person:.3f}, \"\n",
    "                        # f\"val/acc_person: {acc_person:.3f}, \"\n",
    "                        # f\"val/f1_person: {f1_person:.3f}\"\n",
    "                    )\n",
    "                    \n",
    "                    # Switch the model back to training mode\n",
    "                    gate_model.train()\n",
    "                    \n",
    "                    # step += 1\n",
    "                \n",
    "                # Backward pass the model\n",
    "                train_loss.backward()\n",
    "                \n",
    "                # Update the model weights based on computed gradients\n",
    "                optimizer.step()\n",
    "        print()\n",
    "\n",
    "        # ================================================================\n",
    "        # GATE MODEL EVALUATION ON WINDOW DATA\n",
    "        # ================================================================\n",
    "        print_h(\"EVALUATION ON WINDOW DATA\", 64)\n",
    "        \n",
    "        _, acc_window, f1_window, precision_window, recall_window, cm_window = eval_window(gate_model, test_dataloader_GaJuSi, average='weighted')\n",
    "\n",
    "        print(\"acc:\", acc_window)\n",
    "        print(\"f1:\", f1_window)\n",
    "        print(\"precision:\", precision_window)\n",
    "        print(\"recall:\", recall_window)\n",
    "        print(\"cm:\\n\", np.array(cm_window))\n",
    "        print()\n",
    "\n",
    "        gate_in_metrics = {\n",
    "             'window': {\n",
    "                'acc': acc_window,\n",
    "                'f1': f1_window,\n",
    "                'precision': precision_window,\n",
    "                'recall': recall_window,\n",
    "                'cm': cm_window,\n",
    "            },\n",
    "            # 'person_majority_voting': {\n",
    "            #     'acc': acc_person_majority_voting,\n",
    "            #     'f1': f1_person_majority_voting,\n",
    "            #     'precision': precision_person_majority_voting,\n",
    "            #     'recall': recall_person_majority_voting,\n",
    "            #     'cm': cm_person_majority_voting,\n",
    "            # },\n",
    "            # 'person_severity_voting': {\n",
    "            #     'acc': acc_person_severity_voting,\n",
    "            #     'f1': f1_person_severity_voting,\n",
    "            #     'precision': precision_person_severity_voting,\n",
    "            #     'recall': recall_person_severity_voting,\n",
    "            #     'cm': cm_person_severity_voting,\n",
    "            # },\n",
    "            # 'person_max_severity': {\n",
    "            #     'acc': acc_person_max_severity,\n",
    "            #     'f1': f1_person_max_severity,\n",
    "            #     'precision': precision_person_max_severity,\n",
    "            #     'recall': recall_person_max_severity,\n",
    "            #     'cm': cm_person_max_severity,\n",
    "            # },   \n",
    "        }\n",
    "\n",
    "        for metric_type in gate_in_metrics.keys():\n",
    "            update_metrics(gate_metrics[metric_type], gate_in_metrics[metric_type])\n",
    "        \n",
    "        gate_metrics['window']['train_loss']['folds'].append(global_train_loss_list)\n",
    "        gate_metrics['window']['val_loss']['folds'].append(global_val_loss_window_list)\n",
    "\n",
    "        # ================================================================================================\n",
    "        # MoE MODEL\n",
    "        # ================================================================================================\n",
    "        print_h(\"MoE MODEL\", 96)\n",
    "\n",
    "        val_person_dataset_GaJuSi = TensorDataset(X_val_person_GaJuSi, y_val_person_GaJuSi)\n",
    "        test_person_dataset_GaJuSi = TensorDataset(X_test_person_GaJuSi, y_test_person_GaJuSi)\n",
    "\n",
    "        moe_model = HardMoE(experts=expert_model_map.values(), gate=gate_model)\n",
    "\n",
    "        # ================================================================\n",
    "        # MoE MODEL EVALUATION ON PERSON DATA BY MAJORITY VOTING\n",
    "        # ================================================================\n",
    "        print_h(\"EVALUATION ON PERSON DATA BY MAJORITY VOTING\", 64)\n",
    "        _, acc_person_majority_voting, f1_person_majority_voting, precision_person_majority_voting, recall_person_majority_voting, cm_person_majority_voting, *_ = eval_person_majority_voting(moe_model, val_person_dataset_GaJuSi, criterion=None, average='weighted',\n",
    "                                                                                                                                                                                            window_size=window_size, debug=False)\n",
    "        print(\"acc:\", acc_person_majority_voting)\n",
    "        print(\"f1:\", f1_person_majority_voting)\n",
    "        print(\"precision:\", precision_person_majority_voting)\n",
    "        print(\"recall:\", recall_person_majority_voting)\n",
    "        print(\"cm:\\n\", np.array(cm_person_majority_voting))\n",
    "        print()\n",
    "\n",
    "        moe_in_metrics = {\n",
    "             # 'window': {\n",
    "            #     'acc': acc_window,\n",
    "            #     'f1': f1_window,\n",
    "            #     'precision': precision_window,\n",
    "            #     'recall': recall_window,\n",
    "            #     'cm': cm_window,\n",
    "            # },\n",
    "            'person_majority_voting': {\n",
    "                'acc': acc_person_majority_voting,\n",
    "                'f1': f1_person_majority_voting,\n",
    "                'precision': precision_person_majority_voting,\n",
    "                'recall': recall_person_majority_voting,\n",
    "                'cm': cm_person_majority_voting,\n",
    "            },\n",
    "            # 'person_severity_voting': {\n",
    "            #     'acc': acc_person_severity_voting,\n",
    "            #     'f1': f1_person_severity_voting,\n",
    "            #     'precision': precision_person_severity_voting,\n",
    "            #     'recall': recall_person_severity_voting,\n",
    "            #     'cm': cm_person_severity_voting,\n",
    "            # },\n",
    "            # 'person_max_severity': {\n",
    "            #     'acc': acc_person_max_severity,\n",
    "            #     'f1': f1_person_max_severity,\n",
    "            #     'precision': precision_person_max_severity,\n",
    "            #     'recall': recall_person_max_severity,\n",
    "            #     'cm': cm_person_max_severity,\n",
    "            # },   \n",
    "        }\n",
    "\n",
    "        for metric_type in moe_in_metrics.keys():\n",
    "            update_metrics(moe_metrics[metric_type], moe_in_metrics[metric_type])\n",
    "\n",
    "        # ================================================================================================\n",
    "        # GATE MODEL CHECKPOINT SAVING\n",
    "        # ================================================================================================\n",
    "        gate_save_path = os.path.join(gate_save_dir, f'fold_{i_fold+1}.pth')\n",
    "        torch.save(gate_model.state_dict(), gate_save_path)\n",
    "\n",
    "        print(f\"Gate model checkpoint for fold {i_fold+1} is saved to:\", gate_save_path)\n",
    "\n",
    "        # ================================================================================================\n",
    "        # MoE MODEL SAVING\n",
    "        # ================================================================================================\n",
    "        moe_save_path = os.path.join(moe_save_dir, f'fold_{i_fold+1}.pth')\n",
    "        torch.save(moe_model.state_dict(), moe_save_path)\n",
    "\n",
    "        print(f\"MoE model checkpoint for fold {i_fold+1} is saved to:\", moe_save_path)\n",
    "        print()\n",
    "\n",
    "        # DEBUG: Test for only 1 fold\n",
    "        # break\n",
    "\n",
    "save_metrics_to_json(moe_metrics, moe_save_dir, filename='_evaluation_metrics.json')\n",
    "print(\"MoE model evaluation metrics is saved in:\", moe_save_dir)\n",
    "\n",
    "save_metrics_to_json(gate_metrics, gate_save_dir, filename='_evaluation_metrics.json')\n",
    "print(\"Gate model evaluation metrics is saved in:\", gate_save_dir)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "alxxtexxr_py312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
