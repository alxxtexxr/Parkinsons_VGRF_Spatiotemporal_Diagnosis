{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mitlab/miniconda3/envs/alxxtexxr_py312_torch22/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import torch\n",
    "from datetime import datetime\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "from src.utils import (\n",
    "    set_seed, get_device, print_h, \n",
    "    eval_window, eval_person_severity_voting, eval_person_majority_voting, eval_person_max_severity,\n",
    "    init_metrics, update_metrics, save_metrics_to_json,\n",
    ")\n",
    "from src.models import RNNInceptionTime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# class Gate(nn.Module):\n",
    "#     def __init__(self, input_dim, num_experts):\n",
    "#         super().__init__()\n",
    "#         self.linear = nn.Linear(input_dim, num_experts)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         logits = self.linear(x)  # [batch_size, num_experts]\n",
    "#         weights = F.softmax(logits, dim=-1)\n",
    "#         return weights\n",
    "\n",
    "class MoE(nn.Module):\n",
    "    def __init__(self, c_in, seq_len, experts, top_k=1):\n",
    "        super().__init__()\n",
    "        self.top_k = top_k\n",
    "        self.experts = nn.ModuleList(experts)\n",
    "        self.gate = RNNInceptionTime(c_in=c_in, seq_len=seq_len, c_out=len(experts), bidirectional=True)\n",
    "\n",
    "        # Freeze expert parameters\n",
    "        for expert in self.experts:\n",
    "            for param in expert.parameters():\n",
    "                param.requires_grad = False\n",
    "\n",
    "    # def forward(self, x):\n",
    "    #     # Ensure model is on the same device as x\n",
    "    #     self.gate.to(x.device)\n",
    "    #     self.experts.to(x.device)\n",
    "        \n",
    "    #     gate_output = self.gate(x)  # [batch_size, num_experts]\n",
    "        \n",
    "    #     expert_outputs = []\n",
    "    #     for expert in self.experts:\n",
    "    #         expert_out = expert(x)  # [batch_size, input_dim]\n",
    "    #         expert_outputs.append(expert_out)\n",
    "\n",
    "    #     expert_stack = torch.stack(expert_outputs, dim=1)  # [batch_size, num_experts, input_dim]\n",
    "\n",
    "    #     # Reshape gate_output for broadcasting\n",
    "    #     gate_output = gate_output.unsqueeze(-1)  # [batch_size, num_experts, 1]\n",
    "\n",
    "    #     # Weighted sum of all expert outputs\n",
    "    #     moe_output = (gate_output * expert_stack).sum(dim=1)  # [batch_size, input_dim]\n",
    "    #     return moe_output\n",
    "\n",
    "    def forward(self, x):\n",
    "        gate_output = self.gate(x)  # [batch_size, num_experts]\n",
    "        \n",
    "        # Top-k routing\n",
    "        topk_vals, topk_indices = torch.topk(gate_output, self.top_k, dim=-1)\n",
    "        one_hot = torch.zeros_like(gate_output).scatter_(-1, topk_indices, 1.0)\n",
    "        dispatch_mask = one_hot.unsqueeze(-1)  # [batch, num_experts, 1]\n",
    "\n",
    "        expert_outputs = []\n",
    "        for i, expert in enumerate(self.experts):\n",
    "            expert_out = expert(x)  # [batch_size, input_dim]\n",
    "            expert_out = expert_out.unsqueeze(1)  # [batch_size, 1, input_dim]\n",
    "            expert_outputs.append(expert_out)\n",
    "        \n",
    "        expert_stack = torch.cat(expert_outputs, dim=1)  # [batch_size, num_experts, input_dim]\n",
    "\n",
    "        # Combine expert outputs based on gate mask\n",
    "        moe_output = (dispatch_mask * expert_stack).sum(dim=1)  # [batch_size, input_dim]\n",
    "        return moe_output\n",
    "\n",
    "    def train(self, mode=True):\n",
    "        super().train(mode)\n",
    "        for expert in self.experts:\n",
    "            expert.eval()  # Ensure experts stay in eval mode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-04 00:56:31.747813: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-06-04 00:56:31.768357: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-06-04 00:56:31.774769: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-06-04 00:56:31.789059: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-06-04 00:56:32.713054: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random seed: 69\n",
      "Device: cuda\n",
      "Run name tag: Ga_k10_w500_s500_Ju_k10_w500_s500_Si_k10_w500_s500_e20\n"
     ]
    }
   ],
   "source": [
    "seed = 69\n",
    "set_seed(seed)\n",
    "device = get_device()\n",
    "print(\"Device:\", device)\n",
    "\n",
    "# Data and model config\n",
    "k_fold_dir_map = {\n",
    "    'Ga': 'data/preprocessed/Ga_k10_w500_s500_v20250501004633',\n",
    "    'Ju': 'data/preprocessed/Ju_k10_w500_s500_v20250501004709',\n",
    "    'Si': 'data/preprocessed/Si_k10_w500_s500_v20250501213954',\n",
    "}\n",
    "expert_model_dir_map = {\n",
    "    'Ga': 'checkpoints/RNNInceptionTime_bidirectional_Ga_k10_w500_s500_e20_v20250520224322',\n",
    "    'Ju': 'checkpoints/RNNInceptionTime_bidirectional_Ju_k10_w500_s500_e30_v20250520224556',\n",
    "    'Si': 'checkpoints/RNNInceptionTime_bidirectional_Si_k10_w500_s500_e20_v20250520224754',\n",
    "}\n",
    "\n",
    "# Training config\n",
    "n_epoch = 20\n",
    "batch_size = 8\n",
    "n_feat = 16\n",
    "n_class = 4\n",
    "window_size = 500\n",
    "max_vgrf_data_len = 25_000\n",
    "lr = 3e-4\n",
    "\n",
    "# Generate name tag\n",
    "run_name_tag = '_'.join([k_fold_dir.split('/')[-1].rsplit('_v', 1)[0] for k_fold_dir in k_fold_dir_map.values()]) + f'_e{n_epoch}'\n",
    "print(\"Run name tag:\", run_name_tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gate model run name: RNNInceptionTimeGate_bidirectional_Ga_k10_w500_s500_Ju_k10_w500_s500_Si_k10_w500_s500_e20_v20250604005633\n",
      "MoE model run name: RNNInceptionTimeMoE_bidirectional_Ga_k10_w500_s500_Ju_k10_w500_s500_Si_k10_w500_s500_e20_v20250604005633\n",
      "\n",
      "================================================================================================================================\n",
      "                                                            fold_01                                                             \n",
      "================================================================================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================================\n",
      "                                        EXPERT-Ga MODEL                                         \n",
      "================================================================================================\n",
      "================================================================\n",
      "          EVALUATION ON PERSON DATA BY MAJORITY VOTING          \n",
      "================================================================\n",
      "\n",
      "acc: 0.9375\n",
      "f1: 0.9299242424242424\n",
      "precision: 0.9479166666666667\n",
      "recall: 0.9375\n",
      "cm:\n",
      " [[5 0 0 0]\n",
      " [0 6 0 0]\n",
      " [0 0 3 0]\n",
      " [1 0 0 1]]\n",
      "\n",
      "================================================================================================\n",
      "                                        EXPERT-Ju MODEL                                         \n",
      "================================================================================================\n",
      "================================================================\n",
      "          EVALUATION ON PERSON DATA BY MAJORITY VOTING          \n",
      "================================================================\n",
      "\n",
      "acc: 0.9333333333333333\n",
      "f1: 0.9303703703703704\n",
      "precision: 0.9466666666666667\n",
      "recall: 0.9333333333333333\n",
      "cm:\n",
      " [[2 1 0 0]\n",
      " [0 4 0 0]\n",
      " [0 0 7 0]\n",
      " [0 0 0 1]]\n",
      "\n",
      "================================================================================================\n",
      "                                        EXPERT-Si MODEL                                         \n",
      "================================================================================================\n",
      "================================================================\n",
      "          EVALUATION ON PERSON DATA BY MAJORITY VOTING          \n",
      "================================================================\n",
      "\n",
      "acc: 0.875\n",
      "f1: 0.8694444444444445\n",
      "precision: 0.9\n",
      "recall: 0.875\n",
      "cm:\n",
      " [[4 0 0 0]\n",
      " [1 2 0 0]\n",
      " [0 0 1 0]\n",
      " [0 0 0 0]]\n",
      "\n",
      "================================================================================================\n",
      "                                           MoE MODEL                                            \n",
      "================================================================================================\n",
      "================================================================\n",
      "                            TRAINING                            \n",
      "================================================================\n",
      "\n",
      "epoch: 1, train/loss: 2.638, val/loss_window: 0.402, val/acc_window: 0.899, val/f1_window: 0.898, val/loss_person: 1.008, val/acc_person: 0.872, val/f1_person: 0.874, train/time: 35.7s\n",
      "\n",
      "epoch: 2, train/loss: 1.545, val/loss_window: 0.383, val/acc_window: 0.910, val/f1_window: 0.910, val/loss_person: 1.031, val/acc_person: 0.897, val/f1_person: 0.896, train/time: 35.2s\n",
      "\n",
      "epoch: 3, train/loss: 0.514, val/loss_window: 0.205, val/acc_window: 0.942, val/f1_window: 0.941, val/loss_person: 0.817, val/acc_person: 0.897, val/f1_person: 0.896, train/time: 36.2s\n",
      "\n",
      "epoch: 4, train/loss: 0.222, val/loss_window: 0.384, val/acc_window: 0.920, val/f1_window: 0.918, val/loss_person: 1.228, val/acc_person: 0.821, val/f1_person: 0.819, train/time: 35.8s\n",
      "\n",
      "epoch: 5, train/loss: 0.248, val/loss_window: 0.199, val/acc_window: 0.943, val/f1_window: 0.942, val/loss_person: 1.057, val/acc_person: 0.897, val/f1_person: 0.898, train/time: 35.9s\n",
      "\n",
      "epoch: 6, train/loss: 0.205, val/loss_window: 0.222, val/acc_window: 0.950, val/f1_window: 0.950, val/loss_person: 1.424, val/acc_person: 0.872, val/f1_person: 0.874, train/time: 36.2s\n",
      "\n",
      "epoch: 7, train/loss: 0.152, val/loss_window: 0.204, val/acc_window: 0.950, val/f1_window: 0.949, val/loss_person: 1.153, val/acc_person: 0.923, val/f1_person: 0.922, train/time: 35.9s\n",
      "\n",
      "epoch: 8, train/loss: 0.388, val/loss_window: 0.196, val/acc_window: 0.951, val/f1_window: 0.951, val/loss_person: 1.661, val/acc_person: 0.846, val/f1_person: 0.846, train/time: 35.9s\n",
      "\n",
      "epoch: 9, train/loss: 0.174, val/loss_window: 0.298, val/acc_window: 0.941, val/f1_window: 0.941, val/loss_person: 1.575, val/acc_person: 0.846, val/f1_person: 0.846, train/time: 35.9s\n",
      "\n",
      "epoch: 10, train/loss: 0.113, val/loss_window: 0.217, val/acc_window: 0.951, val/f1_window: 0.951, val/loss_person: 1.551, val/acc_person: 0.897, val/f1_person: 0.898, train/time: 35.8s\n",
      "\n",
      "epoch: 11, train/loss: 0.147, val/loss_window: 0.289, val/acc_window: 0.944, val/f1_window: 0.943, val/loss_person: 1.413, val/acc_person: 0.846, val/f1_person: 0.842, train/time: 35.8s\n",
      "\n",
      "epoch: 12, train/loss: 0.102, val/loss_window: 0.240, val/acc_window: 0.957, val/f1_window: 0.957, val/loss_person: 1.470, val/acc_person: 0.923, val/f1_person: 0.924, train/time: 35.9s\n",
      "\n",
      "epoch: 13, train/loss: 0.122, val/loss_window: 0.259, val/acc_window: 0.953, val/f1_window: 0.953, val/loss_person: 1.530, val/acc_person: 0.897, val/f1_person: 0.899, train/time: 35.1s\n",
      "\n",
      "epoch: 14, train/loss: 0.187, val/loss_window: 0.297, val/acc_window: 0.953, val/f1_window: 0.953, val/loss_person: 1.715, val/acc_person: 0.897, val/f1_person: 0.898, train/time: 35.1s\n",
      "\n",
      "epoch: 15, train/loss: 0.128, val/loss_window: 0.240, val/acc_window: 0.960, val/f1_window: 0.960, val/loss_person: 1.676, val/acc_person: 0.897, val/f1_person: 0.898, train/time: 35.2s\n",
      "\n",
      "epoch: 16, train/loss: 0.097, val/loss_window: 0.243, val/acc_window: 0.957, val/f1_window: 0.957, val/loss_person: 2.278, val/acc_person: 0.872, val/f1_person: 0.874, train/time: 36.0s\n",
      "\n",
      "epoch: 17, train/loss: 0.038, val/loss_window: 0.218, val/acc_window: 0.960, val/f1_window: 0.960, val/loss_person: 1.923, val/acc_person: 0.897, val/f1_person: 0.899, train/time: 35.9s\n",
      "\n",
      "epoch: 18, train/loss: 0.119, val/loss_window: 0.255, val/acc_window: 0.959, val/f1_window: 0.959, val/loss_person: 2.068, val/acc_person: 0.872, val/f1_person: 0.874, train/time: 35.9s\n",
      "\n",
      "epoch: 19, train/loss: 0.194, val/loss_window: 0.267, val/acc_window: 0.957, val/f1_window: 0.957, val/loss_person: 2.077, val/acc_person: 0.897, val/f1_person: 0.898, train/time: 35.9s\n",
      "\n",
      "epoch: 20, train/loss: 0.082, val/loss_window: 0.325, val/acc_window: 0.959, val/f1_window: 0.958, val/loss_person: 1.989, val/acc_person: 0.923, val/f1_person: 0.924, train/time: 35.9s\n",
      "\n",
      "================================================================\n",
      "          EVALUATION ON PERSON DATA BY MAJORITY VOTING          \n",
      "================================================================\n",
      "\n",
      "acc: 0.8461538461538461\n",
      "f1: 0.8354700854700854\n",
      "precision: 0.8540433925049309\n",
      "recall: 0.8461538461538461\n",
      "cm:\n",
      " [[10  1  1  0]\n",
      " [ 1 11  1  0]\n",
      " [ 0  0 11  0]\n",
      " [ 1  1  0  1]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Set run names\n",
    "v = datetime.now().strftime(\"%Y%m%d%H%M%S\")\n",
    "gate_run_name = f'RNNInceptionTimeGate_bidirectional_{run_name_tag+'_' if run_name_tag else ''}v{v}'\n",
    "moe_run_name = f'RNNInceptionTimeMoE_bidirectional_{run_name_tag+'_' if run_name_tag else ''}v{v}'\n",
    "print(\"Gate model run name:\", gate_run_name)\n",
    "print(\"MoE model run name:\", moe_run_name)\n",
    "print()\n",
    "\n",
    "# Create save directories\n",
    "# gate_save_dir = 'checkpoints/' + gate_run_name\n",
    "# moe_save_dir = 'checkpoints/' + moe_run_name\n",
    "# os.makedirs(gate_save_dir, exist_ok=True)\n",
    "# os.makedirs(moe_save_dir, exist_ok=True)\n",
    "# print(\"Gate model save directory:\", gate_save_dir)\n",
    "# print(\"MoE model save directory:\", moe_save_dir)\n",
    "# print()\n",
    "\n",
    "# Initialize evaluation metrics\n",
    "gate_metrics = {\n",
    "    'window': init_metrics(['acc', 'f1', 'precision', 'recall', 'cm', 'train_loss', 'val_loss', 'train_time']),\n",
    "    # 'person_majority_voting': init_metrics(['acc', 'f1', 'precision', 'recall', 'cm', 'train_loss', 'val_loss']),\n",
    "    # 'person_severity_voting': init_metrics(['acc', 'f1', 'precision', 'recall', 'cm', 'train_loss', 'val_loss']),\n",
    "    # 'person_max_severity': init_metrics(['acc', 'f1', 'precision', 'recall', 'cm', 'train_loss', 'val_loss']),\n",
    "}\n",
    "moe_metrics = {\n",
    "    # 'window': init_metrics(['acc', 'f1', 'precision', 'recall', 'cm']),\n",
    "    'person_majority_voting': init_metrics(['acc', 'f1', 'precision', 'recall', 'cm']),\n",
    "    # 'person_severity_voting': init_metrics(['acc', 'f1', 'precision', 'recall', 'cm']),\n",
    "    # 'person_max_severity': init_metrics(['acc', 'f1', 'precision', 'recall', 'cm']),\n",
    "}\n",
    "\n",
    "study_label_map = {\n",
    "    'Ga': 0,\n",
    "    'Ju': 1,\n",
    "    'Si': 2,\n",
    "}\n",
    "\n",
    "# for i_fold in range(k_fold):\n",
    "for fold_i_dir_name in sorted(os.listdir(k_fold_dir_map['Ga'])):\n",
    "    # ================================================================================================================================\n",
    "    # FOLD\n",
    "    # ================================================================================================================================\n",
    "    print_h(fold_i_dir_name, 128)\n",
    "    \n",
    "    expert_model_map = {\n",
    "        'Ga': RNNInceptionTime(c_in=n_feat, c_out=n_class, seq_len=window_size, bidirectional=True).to(device),\n",
    "        'Ju': RNNInceptionTime(c_in=n_feat, c_out=n_class, seq_len=window_size, bidirectional=True).to(device),\n",
    "        'Si': RNNInceptionTime(c_in=n_feat, c_out=n_class, seq_len=window_size, bidirectional=True).to(device),\n",
    "    }\n",
    "\n",
    "    X_train_window_GaJuSi = torch.empty(0, window_size, n_feat).float()\n",
    "    y_train_window_GaJuSi = torch.empty(0).long()\n",
    "    study_labels_train_window_GaJuSi = torch.empty(0).long()\n",
    "    \n",
    "    X_val_window_GaJuSi = torch.empty(0, window_size, n_feat).float()\n",
    "    y_val_window_GaJuSi = torch.empty(0).long()\n",
    "    study_labels_val_window_GaJuSi = torch.empty(0).long()\n",
    "\n",
    "    X_test_window_GaJuSi = torch.empty(0, window_size, n_feat).float()\n",
    "    y_test_window_GaJuSi = torch.empty(0).long()\n",
    "    study_labels_test_window_GaJuSi = torch.empty(0).long()\n",
    "\n",
    "    X_val_person_GaJuSi = torch.empty(0, max_vgrf_data_len, n_feat).float()\n",
    "    y_val_person_GaJuSi = torch.empty(0).long()\n",
    "    # study_labels_val_person_GaJuSi = torch.empty(0).long()\n",
    "\n",
    "    X_test_person_GaJuSi = torch.empty(0, max_vgrf_data_len, n_feat).float()\n",
    "    y_test_person_GaJuSi = torch.empty(0).long()\n",
    "    # study_labels_test_person_GaJuSi = torch.empty(0).long()\n",
    "\n",
    "    for study, k_fold_dir in k_fold_dir_map.items():\n",
    "        # ================================================================================================\n",
    "        # EXPERT MODEL\n",
    "        # ================================================================================================\n",
    "        print_h(f\"EXPERT-{study} MODEL\", 96)\n",
    "        \n",
    "        fold_i_dir = os.path.join(k_fold_dir, fold_i_dir_name)\n",
    "\n",
    "        X_train_window = torch.tensor(np.load(os.path.join(fold_i_dir, f'X_train_window.npy'))).float()\n",
    "        y_train_window = torch.tensor(np.load(os.path.join(fold_i_dir, f'y_train_window.npy'))).long()\n",
    "        study_labels_train_window = torch.tensor([study_label_map[study]] * len(y_train_window)).long()\n",
    "        X_train_window_GaJuSi = torch.cat((X_train_window_GaJuSi, X_train_window), dim=0)\n",
    "        y_train_window_GaJuSi = torch.cat((y_train_window_GaJuSi, y_train_window), dim=0)\n",
    "        study_labels_train_window_GaJuSi = torch.cat((study_labels_train_window_GaJuSi, study_labels_train_window), dim=0)\n",
    "\n",
    "        X_val_window = torch.tensor(np.load(os.path.join(fold_i_dir, f'X_val_window.npy'))).float()\n",
    "        y_val_window = torch.tensor(np.load(os.path.join(fold_i_dir, f'y_val_window.npy'))).long()\n",
    "        study_labels_val_window = torch.tensor([study_label_map[study]] * len(y_val_window)).long()\n",
    "        X_val_window_GaJuSi = torch.cat((X_val_window_GaJuSi, X_val_window), dim=0)\n",
    "        y_val_window_GaJuSi = torch.cat((y_val_window_GaJuSi, y_val_window), dim=0)\n",
    "        study_labels_val_window_GaJuSi = torch.cat((study_labels_val_window_GaJuSi, study_labels_val_window), dim=0)\n",
    "\n",
    "        X_test_window = torch.tensor(np.load(os.path.join(fold_i_dir, f'X_test_window.npy'))).float()\n",
    "        y_test_window = torch.tensor(np.load(os.path.join(fold_i_dir, f'y_test_window.npy'))).long()\n",
    "        study_labels_test_window = torch.tensor([study_label_map[study]] * len(y_test_window)).long()\n",
    "        X_test_window_GaJuSi = torch.cat((X_test_window_GaJuSi, X_test_window), dim=0)\n",
    "        y_test_window_GaJuSi = torch.cat((y_test_window_GaJuSi, y_test_window), dim=0)\n",
    "        study_labels_test_window_GaJuSi = torch.cat((study_labels_test_window_GaJuSi, study_labels_test_window), dim=0)\n",
    "\n",
    "        X_val_person = torch.tensor(np.load(os.path.join(fold_i_dir, f'X_val_person.npy'))).float()\n",
    "        y_val_person = torch.tensor(np.load(os.path.join(fold_i_dir, f'y_val_person.npy'))).long()\n",
    "        X_val_person_GaJuSi = torch.cat((X_val_person_GaJuSi, X_val_person), dim=0)\n",
    "        y_val_person_GaJuSi = torch.cat((y_val_person_GaJuSi, y_val_person), dim=0)\n",
    "\n",
    "        X_test_person = torch.tensor(np.load(os.path.join(fold_i_dir, f'X_test_person.npy'))).float()\n",
    "        y_test_person = torch.tensor(np.load(os.path.join(fold_i_dir, f'y_test_person.npy'))).long()\n",
    "        X_test_person_GaJuSi = torch.cat((X_test_person_GaJuSi, X_test_person), dim=0)\n",
    "        y_test_person_GaJuSi = torch.cat((y_test_person_GaJuSi, y_test_person), dim=0)\n",
    "\n",
    "        train_window_dataset = TensorDataset(X_train_window, y_train_window)\n",
    "        val_window_dataset = TensorDataset(X_val_window, y_val_window)\n",
    "        test_window_dataset = TensorDataset(X_test_window, y_test_window)\n",
    "        \n",
    "        val_person_dataset = TensorDataset(X_val_person, y_val_person)\n",
    "        test_person_dataset = TensorDataset(X_test_person, y_test_person)\n",
    "\n",
    "        train_dataloader = DataLoader(train_window_dataset, batch_size=batch_size, shuffle=True)\n",
    "        val_dataloader = DataLoader(val_window_dataset, batch_size=batch_size, shuffle=False)\n",
    "        test_dataloader = DataLoader(test_window_dataset, batch_size=batch_size, shuffle=False)\n",
    "        \n",
    "        expert_model = expert_model_map[study]\n",
    "\n",
    "        # Load pretrained model\n",
    "        model_i_path = os.path.join(expert_model_dir_map[study], fold_i_dir_name + '.pth')\n",
    "        expert_model.load_state_dict(torch.load(model_i_path, map_location=device))\n",
    "    \n",
    "        # ================================================================\n",
    "        # EXPERT MODEL EVALUATION ON PERSON DATA BY MAJORITY VOTING\n",
    "        # ================================================================\n",
    "        print_h(\"EVALUATION ON PERSON DATA BY MAJORITY VOTING\", 64)\n",
    "        _, acc_person_majority_voting, f1_person_majority_voting, precision_person_majority_voting, recall_person_majority_voting, cm_person_majority_voting, *_ = eval_person_majority_voting(expert_model, test_person_dataset, criterion=None, average='weighted',\n",
    "                                                                                                                                                                                                window_size=window_size, debug=False, seed=seed)\n",
    "        print(\"acc:\", acc_person_majority_voting)\n",
    "        print(\"f1:\", f1_person_majority_voting)\n",
    "        print(\"precision:\", precision_person_majority_voting)\n",
    "        print(\"recall:\", recall_person_majority_voting)\n",
    "        print(\"cm:\\n\", np.array(cm_person_majority_voting))\n",
    "        print()\n",
    "\n",
    "    # ================================================================================================\n",
    "    # MoE MODEL\n",
    "    # ================================================================================================\n",
    "    print_h(\"MoE MODEL\", 96)\n",
    "\n",
    "    # For MoE model training\n",
    "    train_window_dataset_GaJuSi = TensorDataset(X_train_window_GaJuSi, y_train_window_GaJuSi)\n",
    "    val_window_dataset_GaJuSi = TensorDataset(X_val_window_GaJuSi, y_val_window_GaJuSi)\n",
    "    test_window_dataset_GaJuSi = TensorDataset(X_test_window_GaJuSi, y_test_window_GaJuSi)\n",
    "\n",
    "    # For gate model training\n",
    "    # train_window_dataset_GaJuSi = TensorDataset(X_train_window_GaJuSi, study_labels_train_window_GaJuSi)\n",
    "    # val_window_dataset_GaJuSi = TensorDataset(X_val_window_GaJuSi, study_labels_val_window_GaJuSi)\n",
    "    # test_window_dataset_GaJuSi = TensorDataset(X_test_window_GaJuSi, study_labels_test_window_GaJuSi)\n",
    "\n",
    "    train_dataloader_GaJuSi = DataLoader(train_window_dataset_GaJuSi, batch_size=batch_size, shuffle=True)\n",
    "    val_dataloader_GaJuSi = DataLoader(val_window_dataset_GaJuSi, batch_size=batch_size, shuffle=False)\n",
    "    test_dataloader_GaJuSi = DataLoader(test_window_dataset_GaJuSi, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    val_person_dataset_GaJuSi = TensorDataset(X_val_person_GaJuSi, y_val_person_GaJuSi)\n",
    "    test_person_dataset_GaJuSi = TensorDataset(X_test_person_GaJuSi, y_test_person_GaJuSi)\n",
    "\n",
    "    # ================================\n",
    "    # TRAINING\n",
    "    # ================================\n",
    "    print_h(\"TRAINING\", 64)\n",
    "    moe_model = MoE(c_in=n_feat, seq_len=window_size, experts=expert_model_map.values())\n",
    "    \n",
    "    # Initialize optimizer and loss function\n",
    "    optimizer = torch.optim.Adam(moe_model.parameters(), lr=lr)\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "    # Swith the model to training mode\n",
    "    moe_model.train()\n",
    "    \n",
    "    # Loop training epochs\n",
    "    global_val_loss_window_list = []\n",
    "    global_val_loss_person_list = []\n",
    "    global_train_loss_list = []\n",
    "    global_train_time_list = []\n",
    "    train_loss_list = []\n",
    "    \n",
    "    for epoch in range(n_epoch):\n",
    "        start_time = time.time()\n",
    "        \n",
    "        # Loop training batches\n",
    "        for iter, (X_train, y_train) in enumerate(train_dataloader_GaJuSi):\n",
    "            # Flush the computed gradients\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            X_train = X_train.to(device)\n",
    "            y_train = y_train.to(device)\n",
    "            \n",
    "            # Feed forward the model\n",
    "            X_train = X_train.permute(0, 2, 1)\n",
    "            y_pred = moe_model(X_train)\n",
    "\n",
    "            # Compute training loss\n",
    "            train_loss = criterion(y_pred, y_train)\n",
    "            train_loss_list.append(train_loss)\n",
    "\n",
    "            # Backward pass the model\n",
    "            train_loss.backward()\n",
    "            \n",
    "            # Update the model weights based on computed gradients\n",
    "            optimizer.step()\n",
    "        \n",
    "        # Compute training time\n",
    "        train_time = time.time() - start_time\n",
    "        global_train_time_list.append(train_time)\n",
    "\n",
    "        # ================================\n",
    "        # VALIDATION\n",
    "        # ================================\n",
    "        avg_val_loss_window, acc_window, f1_window, *_ = eval_window(moe_model, val_dataloader_GaJuSi, criterion, average='weighted')\n",
    "        avg_val_loss_person, acc_person, f1_person, *_ = eval_person_majority_voting(moe_model, val_person_dataset_GaJuSi, criterion=criterion, average='weighted',\n",
    "                                                                                          window_size=window_size)\n",
    "        \n",
    "        global_val_loss_window_list.append(avg_val_loss_window)\n",
    "        global_val_loss_person_list.append(avg_val_loss_person)\n",
    "        \n",
    "        # Compute the average training loss for each epoch\n",
    "        avg_train_loss = sum(train_loss_list) / len(train_dataloader)\n",
    "        global_train_loss_list.append(avg_train_loss.item())\n",
    "        train_loss_list = []\n",
    "        \n",
    "        # ================================\n",
    "        # LOGGING\n",
    "        # ================================\n",
    "        print(f\"epoch: {epoch+1}, \"\n",
    "              f\"train/loss: {avg_train_loss:.3f}, \"\n",
    "              f\"val/loss_window: {avg_val_loss_window:.3f}, \"\n",
    "              f\"val/acc_window: {acc_window:.3f}, \"\n",
    "              f\"val/f1_window: {f1_window:.3f}, \"\n",
    "              f\"val/loss_person: {avg_val_loss_person:.3f}, \"\n",
    "              f\"val/acc_person: {acc_person:.3f}, \"\n",
    "              f\"val/f1_person: {f1_person:.3f}, \"\n",
    "              f\"train/time: {train_time:.1f}s\"\n",
    "        )\n",
    "        \n",
    "        # Switch the model back to training mode\n",
    "        moe_model.train()\n",
    "    print()\n",
    "\n",
    "    # ================================================================\n",
    "    # MoE MODEL EVALUATION ON PERSON DATA BY MAJORITY VOTING\n",
    "    # ================================================================\n",
    "    print_h(\"EVALUATION ON PERSON DATA BY MAJORITY VOTING\", 64)\n",
    "    _, acc_person_majority_voting, f1_person_majority_voting, precision_person_majority_voting, recall_person_majority_voting, cm_person_majority_voting, *_ = eval_person_majority_voting(moe_model, test_person_dataset_GaJuSi, criterion=None, average='weighted',\n",
    "                                                                                                                                                                                           window_size=window_size, debug=False)\n",
    "    print(\"acc:\", acc_person_majority_voting)\n",
    "    print(\"f1:\", f1_person_majority_voting)\n",
    "    print(\"precision:\", precision_person_majority_voting)\n",
    "    print(\"recall:\", recall_person_majority_voting)\n",
    "    print(\"cm:\\n\", np.array(cm_person_majority_voting))\n",
    "    print()\n",
    "\n",
    "    moe_in_metrics = {\n",
    "        # 'window': {\n",
    "        #     'acc': acc_window,\n",
    "        #     'f1': f1_window,\n",
    "        #     'precision': precision_window,\n",
    "        #     'recall': recall_window,\n",
    "        #     'cm': cm_window,\n",
    "        # },\n",
    "        'person_majority_voting': {\n",
    "            'acc': acc_person_majority_voting,\n",
    "            'f1': f1_person_majority_voting,\n",
    "            'precision': precision_person_majority_voting,\n",
    "            'recall': recall_person_majority_voting,\n",
    "            'cm': cm_person_majority_voting,\n",
    "        },\n",
    "        # 'person_severity_voting': {\n",
    "        #     'acc': acc_person_severity_voting,\n",
    "        #     'f1': f1_person_severity_voting,\n",
    "        #     'precision': precision_person_severity_voting,\n",
    "        #     'recall': recall_person_severity_voting,\n",
    "        #     'cm': cm_person_severity_voting,\n",
    "        # },\n",
    "        # 'person_max_severity': {\n",
    "        #     'acc': acc_person_max_severity,\n",
    "        #     'f1': f1_person_max_severity,\n",
    "        #     'precision': precision_person_max_severity,\n",
    "        #     'recall': recall_person_max_severity,\n",
    "        #     'cm': cm_person_max_severity,\n",
    "        # },   \n",
    "    }\n",
    "\n",
    "    for metric_type in moe_in_metrics.keys():\n",
    "        update_metrics(moe_metrics[metric_type], moe_in_metrics[metric_type])\n",
    "\n",
    "    # ================================================================================================\n",
    "    # MoE MODEL SAVING\n",
    "    # ================================================================================================\n",
    "    # moe_save_path = os.path.join(moe_save_dir, f'{fold_i_dir_name}.pth')\n",
    "    # torch.save(moe_model.state_dict(), moe_save_path)\n",
    "\n",
    "    # print(f\"MoE model checkpoint for {fold_i_dir_name} is saved to:\", moe_save_path)\n",
    "    # print()\n",
    "\n",
    "    # DEBUG: Test for only 1 fold\n",
    "    break\n",
    "\n",
    "# save_metrics_to_json(moe_metrics, moe_save_dir, filename='_evaluation_metrics.json')\n",
    "# print(\"MoE model evaluation metrics is saved in:\", moe_save_dir)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "alxxtexxr_py312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
